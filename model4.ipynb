{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":133060,"status":"ok","timestamp":1680956695981,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"AYTJICU8mTMX","outputId":"f09dac00-74bd-4626-8eaa-88be8974f6e5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1172,"status":"ok","timestamp":1680956697148,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"nKm2GBdCmU2s","outputId":"3f80fcf8-e6fb-49cd-ca4d-5a2f32b7ff2a"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/data_visualization/datavis_data\n"]}],"source":["cd /content/gdrive/MyDrive/data_visualization/datavis_data/"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7987,"status":"ok","timestamp":1680956705130,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"lte9XrLRhFVx"},"outputs":[],"source":["import os\n","import collections\n","import pandas as pd\n","import numpy as np\n","import functools\n","import matplotlib.pyplot as plt\n","import cv2\n","\n","from sklearn import preprocessing \n","\n","\n","import xml.etree.ElementTree as ET\n","\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2\n","\n","import torch\n","import torchvision\n","\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection import FasterRCNN\n","from torchvision.models.detection.rpn import AnchorGenerator\n","\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.data import SequentialSampler"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19688,"status":"ok","timestamp":1680956724814,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"8oUILFDVg_-P","outputId":"a1a0c610-5f47-45c8-b372-5fbcd8fb7a86"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{},"execution_count":4}],"source":["XML_PATH = \"annotation\"\n","IMG_PATH = \"train\"\n","XML_FILES = [os.path.join(XML_PATH, f) for f in os.listdir(XML_PATH)]\n","XML_FILES = XML_FILES[:1000] #first 1000\n","\n","len(XML_FILES)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"O_U86BV5g_-Z","executionInfo":{"status":"ok","timestamp":1680956728167,"user_tz":-330,"elapsed":3,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["class XmlParser(object):\n","\n","    def __init__(self,xml_file):\n","\n","        self.xml_file = self.filter(xml_file)\n","        \n","        # path to the image file = name of annotation file\n","        self.img_name = xml_file.split('/')[1].split('.')[0]+\".jpg\";\n","        self.img_path = os.path.join(IMG_PATH, self.img_name)\n","\n","        # image id \n","        self.image_id = self.img_name.split('.')[0];\n","\n","        # names of the classes contained in the xml file\n","        self.names = self._get_names()\n","        # coordinates of the bounding boxes\n","        self.boxes = self._get_bndbox()\n","\n","    def filter(self,xml_file):\n","\n","        filtered_data = []\n","\n","        f = open(xml_file, 'r')\n","\n","        for line in f:\n","            data = line.split(',')\n","            if data[5]!='0' and (data[5]=='7' or data[5]=='8'):\n","                data = [int(x.strip()) for x in data]\n","                filtered_data.append(data)\n","\n","                #augmentation for people\n","                if data[5]=='1' or data[5]=='2':\n","                  filtered_data.append(data)\n","\n","        return filtered_data\n","\n","    def _get_names(self):\n","\n","        label_dict = {\n","                      0 : \"Ignore\",\n","                      1 : \"Pedestrian\",\n","                      2 : \"People\",\n","                      3 : \"Bicycle\",\n","                      4 : \"Car\",\n","                      5 : \"Van\",\n","                      6 : \"Truck\",\n","                      7 : \"Tricycle\",\n","                      8 : \"Awning-tricycle\",\n","                      9 : \"Bus\",\n","                      10 : \"Motor\",\n","                      11 : \"Others\"\n","                    }\n","\n","        names = []\n","\n","        for data in self.xml_file:\n","              class_id = data[5]\n","              names.append(label_dict[class_id])\n","\n","        return np.array(names)\n","\n","    def _get_bndbox(self):\n","\n","        boxes = []\n","\n","        for data in self.xml_file:\n","            \n","            coordinates = []\n","            coordinates.append(np.int32(data[0])) #xmin\n","            coordinates.append(np.int32(np.float32(data[1]))) #ymin\n","            coordinates.append(np.int32(data[2]+data[0])) #xmax\n","            coordinates.append(np.int32(data[3]+data[1])) #ymax\n","            boxes.append(coordinates)\n","\n","        return np.array(boxes)\n","\n","# xml = XmlParser('Annotations/0000007_05999_d_0000038.txt')"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":106786,"status":"ok","timestamp":1680956844489,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"_NvoeGhmi6Rh","outputId":"51c8684c-c98c-4a18-daec-a197713d6758"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["939"]},"metadata":{},"execution_count":7}],"source":["def xml_files_to_df(xml_files):\n","    \n","    \"\"\"\"Return pandas dataframe from list of XML files.\"\"\"\n","    \n","    names = []\n","    boxes = []\n","    image_id = []\n","    xml_path = []\n","    img_path = []\n","    for file in xml_files:\n","        xml = XmlParser(file)\n","        names.extend(xml.names)\n","        boxes.extend(xml.boxes)\n","        image_id.extend([xml.image_id] * len(xml.names))\n","        xml_path.extend([xml.xml_file] * len(xml.names))\n","        img_path.extend([xml.img_path] * len(xml.names))\n","    a = {\"img_id\": image_id,\n","         \"names\": names,\n","         \"boxes\": boxes,\n","         \"xml_path\":xml_path,\n","         \"img_path\":img_path}\n","    \n","    df = pd.DataFrame.from_dict(a, orient='index')\n","    df = df.transpose()\n","    \n","    return df\n","\n","df = xml_files_to_df(XML_FILES)\n","df.head()\n","df.shape[0]"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1680956846481,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"UL91oDD4g_-c","outputId":"248765eb-11b7-4a5d-e581-ca7a2a788905"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tricycle           633\n","Awning-tricycle    306\n","Name: names, dtype: int64"]},"metadata":{},"execution_count":8}],"source":["# check values for per class\n","df['names'].value_counts()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1680956846481,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"Ui-v8WIHg_-d","outputId":"c9ce69b3-34b7-45a0-ad7e-66e68c6e8d85"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0        [835, 283, 842, 292]\n","1         [723, 72, 762, 100]\n","2        [712, 298, 771, 348]\n","3        [299, 360, 365, 392]\n","4      [1335, 738, 1365, 769]\n","                ...          \n","934      [971, 480, 993, 512]\n","935    [1043, 390, 1062, 424]\n","936      [1596, 27, 1604, 38]\n","937      [1582, 18, 1591, 27]\n","938      [1681, 57, 1693, 71]\n","Name: boxes, Length: 939, dtype: object"]},"metadata":{},"execution_count":9}],"source":["df['boxes']"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38,"status":"ok","timestamp":1680956846482,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"D_sTTUxBg_-e","outputId":"5e5970f3-b99f-45fc-de40-a09fc2c74f16"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py:3473: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  if (await self.run_code(code, result,  async_=asy)):\n"]}],"source":["# classes need to be in int form so we use LabelEncoder for this task\n","enc = preprocessing.LabelEncoder()\n","df['labels'] = enc.fit_transform(df['names'])\n","df['labels'] = np.stack(df['labels'][i]+1 for i in range(len(df['labels']))) "]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1680956846483,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"byc5kANsg_-f","outputId":"3839731a-af81-421c-ae5c-a1bdc349d2eb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["names            labels\n","Tricycle         2         633\n","Awning-tricycle  1         306\n","dtype: int64"]},"metadata":{},"execution_count":11}],"source":["classes = df[['names','labels']].value_counts()\n","classes"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1680956846484,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"9a-7b1bKsj89","outputId":"adbac5ce-ae6a-43eb-a89b-643fd9a94640"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                    img_id            names                   boxes  \\\n","0  9999994_00000_d_0000055  Awning-tricycle    [835, 283, 842, 292]   \n","1  9999990_00000_d_0000013  Awning-tricycle     [723, 72, 762, 100]   \n","2  9999991_00000_d_0000020  Awning-tricycle    [712, 298, 771, 348]   \n","3  9999990_00000_d_0000030  Awning-tricycle    [299, 360, 365, 392]   \n","4  9999991_00000_d_0000031  Awning-tricycle  [1335, 738, 1365, 769]   \n","\n","                            xml_path                           img_path  \\\n","0     [[835, 283, 7, 9, 1, 8, 0, 1]]  train/9999994_00000_d_0000055.jpg   \n","1    [[723, 72, 39, 28, 1, 8, 0, 1]]  train/9999990_00000_d_0000013.jpg   \n","2   [[712, 298, 59, 50, 1, 8, 0, 1]]  train/9999991_00000_d_0000020.jpg   \n","3   [[299, 360, 66, 32, 1, 8, 0, 1]]  train/9999990_00000_d_0000030.jpg   \n","4  [[1335, 738, 30, 31, 1, 8, 0, 1]]  train/9999991_00000_d_0000031.jpg   \n","\n","   labels  \n","0       1  \n","1       1  \n","2       1  \n","3       1  \n","4       1  "],"text/html":["\n","  <div id=\"df-f2a4fbdd-d722-4bfc-b3e1-867232d99fa8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>img_id</th>\n","      <th>names</th>\n","      <th>boxes</th>\n","      <th>xml_path</th>\n","      <th>img_path</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>Awning-tricycle</td>\n","      <td>[835, 283, 842, 292]</td>\n","      <td>[[835, 283, 7, 9, 1, 8, 0, 1]]</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9999990_00000_d_0000013</td>\n","      <td>Awning-tricycle</td>\n","      <td>[723, 72, 762, 100]</td>\n","      <td>[[723, 72, 39, 28, 1, 8, 0, 1]]</td>\n","      <td>train/9999990_00000_d_0000013.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9999991_00000_d_0000020</td>\n","      <td>Awning-tricycle</td>\n","      <td>[712, 298, 771, 348]</td>\n","      <td>[[712, 298, 59, 50, 1, 8, 0, 1]]</td>\n","      <td>train/9999991_00000_d_0000020.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9999990_00000_d_0000030</td>\n","      <td>Awning-tricycle</td>\n","      <td>[299, 360, 365, 392]</td>\n","      <td>[[299, 360, 66, 32, 1, 8, 0, 1]]</td>\n","      <td>train/9999990_00000_d_0000030.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9999991_00000_d_0000031</td>\n","      <td>Awning-tricycle</td>\n","      <td>[1335, 738, 1365, 769]</td>\n","      <td>[[1335, 738, 30, 31, 1, 8, 0, 1]]</td>\n","      <td>train/9999991_00000_d_0000031.jpg</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2a4fbdd-d722-4bfc-b3e1-867232d99fa8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f2a4fbdd-d722-4bfc-b3e1-867232d99fa8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f2a4fbdd-d722-4bfc-b3e1-867232d99fa8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}],"source":["df.head()"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"ZPxyczp5g_-g","executionInfo":{"status":"ok","timestamp":1680956846485,"user_tz":-330,"elapsed":29,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["classes = {\n","                      1 : \"Tricycle\",\n","                      2 : \"Awning-Tricycle\",\n","                    }"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1680956846486,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"NFVN1DODg_-h","outputId":"7643ecae-9982-4741-9069-a03e2ab9798b"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py:3473: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  if (await self.run_code(code, result,  async_=asy)):\n"]}],"source":["#bounding box coordinates point need to be in separate columns\n","\n","df['xmin'] = -1\n","df['ymin'] = -1\n","df['xmax'] = -1\n","df['ymax'] = -1\n","\n","df[['xmin','ymin','xmax','ymax']]=np.stack(df['boxes'][i] for i in range(len(df['boxes'])))\n","\n","df.drop(columns=['boxes'], inplace=True)\n","df['xmin'] = df['xmin'].astype(float)\n","df['ymin'] = df['ymin'].astype(float)\n","df['xmax'] = df['xmax'].astype(float)\n","df['ymax'] = df['ymax'].astype(float)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1680956846486,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"OpjbwFXAg_-i","outputId":"de3da942-0ab7-4598-8c86-42721bd8c898"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                    img_id                           xml_path  \\\n","0  9999994_00000_d_0000055     [[835, 283, 7, 9, 1, 8, 0, 1]]   \n","1  9999990_00000_d_0000013    [[723, 72, 39, 28, 1, 8, 0, 1]]   \n","2  9999991_00000_d_0000020   [[712, 298, 59, 50, 1, 8, 0, 1]]   \n","3  9999990_00000_d_0000030   [[299, 360, 66, 32, 1, 8, 0, 1]]   \n","4  9999991_00000_d_0000031  [[1335, 738, 30, 31, 1, 8, 0, 1]]   \n","\n","                            img_path  labels    xmin   ymin    xmax   ymax  \n","0  train/9999994_00000_d_0000055.jpg       1   835.0  283.0   842.0  292.0  \n","1  train/9999990_00000_d_0000013.jpg       1   723.0   72.0   762.0  100.0  \n","2  train/9999991_00000_d_0000020.jpg       1   712.0  298.0   771.0  348.0  \n","3  train/9999990_00000_d_0000030.jpg       1   299.0  360.0   365.0  392.0  \n","4  train/9999991_00000_d_0000031.jpg       1  1335.0  738.0  1365.0  769.0  "],"text/html":["\n","  <div id=\"df-203e7dd9-0ce4-4f7b-9ec4-e435b3465c7d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>img_id</th>\n","      <th>xml_path</th>\n","      <th>img_path</th>\n","      <th>labels</th>\n","      <th>xmin</th>\n","      <th>ymin</th>\n","      <th>xmax</th>\n","      <th>ymax</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>[[835, 283, 7, 9, 1, 8, 0, 1]]</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>1</td>\n","      <td>835.0</td>\n","      <td>283.0</td>\n","      <td>842.0</td>\n","      <td>292.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9999990_00000_d_0000013</td>\n","      <td>[[723, 72, 39, 28, 1, 8, 0, 1]]</td>\n","      <td>train/9999990_00000_d_0000013.jpg</td>\n","      <td>1</td>\n","      <td>723.0</td>\n","      <td>72.0</td>\n","      <td>762.0</td>\n","      <td>100.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9999991_00000_d_0000020</td>\n","      <td>[[712, 298, 59, 50, 1, 8, 0, 1]]</td>\n","      <td>train/9999991_00000_d_0000020.jpg</td>\n","      <td>1</td>\n","      <td>712.0</td>\n","      <td>298.0</td>\n","      <td>771.0</td>\n","      <td>348.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9999990_00000_d_0000030</td>\n","      <td>[[299, 360, 66, 32, 1, 8, 0, 1]]</td>\n","      <td>train/9999990_00000_d_0000030.jpg</td>\n","      <td>1</td>\n","      <td>299.0</td>\n","      <td>360.0</td>\n","      <td>365.0</td>\n","      <td>392.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9999991_00000_d_0000031</td>\n","      <td>[[1335, 738, 30, 31, 1, 8, 0, 1]]</td>\n","      <td>train/9999991_00000_d_0000031.jpg</td>\n","      <td>1</td>\n","      <td>1335.0</td>\n","      <td>738.0</td>\n","      <td>1365.0</td>\n","      <td>769.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-203e7dd9-0ce4-4f7b-9ec4-e435b3465c7d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-203e7dd9-0ce4-4f7b-9ec4-e435b3465c7d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-203e7dd9-0ce4-4f7b-9ec4-e435b3465c7d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}],"source":["# drop names column since we dont need it anymore\n","df.drop(columns=['names'], inplace=True)\n","df.head()"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1680956846487,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"m7RqwLzZg_-j","outputId":"69a9b9fb-0c73-4ab4-fcc6-60b8272f9b4e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["449"]},"metadata":{},"execution_count":16}],"source":["len(df['img_id'].unique())"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1680956846488,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"JYr0ORPlg_-j","outputId":"024283a8-f3c9-4d2a-a048-f78ef6540fee"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["445"]},"metadata":{},"execution_count":17}],"source":["image_ids = df['img_id'].unique()\n","valid_ids = image_ids[-4:]\n","train_ids = image_ids[:-4]\n","len(train_ids)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1680956846489,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"W96Vu4Hpg_-k","outputId":"6b2aec3c-2c91-4500-acb0-626488b3185a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((12, 8), (927, 8))"]},"metadata":{},"execution_count":18}],"source":["valid_df = df[df['img_id'].isin(valid_ids)]\n","train_df = df[df['img_id'].isin(train_ids)]\n","valid_df.shape, train_df.shape"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"EvCx_P7mg_-k","executionInfo":{"status":"ok","timestamp":1680956855154,"user_tz":-330,"elapsed":8685,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["!pip install -q albumentations\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import numpy as np\n","import os\n","from albumentations import RandomRotate90\n","from tensorflow.keras import mixed_precision\n","import gc"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"LX7lOczzg_-l","executionInfo":{"status":"ok","timestamp":1680956855155,"user_tz":-330,"elapsed":13,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["def func(image):\n","    Trgb2lms =np.array( [\n","          np.array([17.8824, 43.5161, 4.1194]),\n","          np.array([3.4557,27.1154, 3.8671]),\n","          np.array([0.0300, 0.1843, 1.4671]) \n","      ])\n","    \n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    x,y,z = image.shape\n","#     print(image.shape)\n","    cvd_due = np.array([\n","                     np.array([1 ,0, 0]),   \n","                     np.array([0.494207, 0, 1.24827]),   \n","                     np.array([0, 0, 1]),   \n","    ])\n","    INV_Trgb2lms = np.linalg.inv(Trgb2lms) \n","\n","#     print(image.transpose(2, 0, 1).shape)\n","    out = np.dot(INV_Trgb2lms, cvd_due)\n","    out = np.dot(out, Trgb2lms)\n","    out = np.dot(out, image.transpose(2, 0, 1).reshape(3,-1)) \n","    out = out.reshape(3,x,y).transpose(1, 2, 0)\n","    out = cv2.cvtColor(np.float32(out), cv2.COLOR_RGB2BGR)\n","\n","    return out\n","  "]},{"cell_type":"code","execution_count":21,"metadata":{"id":"D-2_NuLkg_-m","executionInfo":{"status":"ok","timestamp":1680956855156,"user_tz":-330,"elapsed":13,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["class VOCDataset(Dataset):\n","    \n","    def __init__(self, dataframe, image_dir, transforms=None):\n","        super().__init__()\n","        \n","        self.image_ids = dataframe['img_id'].unique()\n","        self.df = dataframe\n","        self.image_dir = image_dir\n","        self.transforms = transforms\n","    \n","    def __getitem__(self, index: int):\n","        image_id = self.image_ids[index]\n","        records = self.df[self.df['img_id'] == image_id]\n","        \n","        image = cv2.imread(f'{self.image_dir}/{image_id}.jpg', cv2.IMREAD_COLOR)\n","        image = func(image)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n","        image /= 255.0\n","        rows, cols = image.shape[:2]\n","        \n","        boxes = records[['xmin', 'ymin', 'xmax', 'ymax']].values\n","        \n","       \n","        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n","        area = torch.as_tensor(area, dtype=torch.float32)\n","        \n","        label = records['labels'].values\n","        labels = torch.as_tensor(label, dtype=torch.int64)\n","        \n","        # suppose all instances are not crowd\n","        iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n","        \n","        target = {}\n","        target['boxes'] = boxes\n","        target['labels'] = labels\n","        # target['masks'] = None\n","        target['image_id'] = torch.tensor([index])\n","        target['area'] = area\n","        target['iscrowd'] = iscrowd\n","        \n","        if self.transforms:\n","            sample = {\n","                'image': image,\n","                'bboxes': target['boxes'],\n","                'labels': labels\n","            }\n","            sample = self.transforms(**sample)\n","            image = sample['image']\n","            \n","            target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1,0)\n","            \n","            return image, target\n","        \n","    def __len__(self) -> int:\n","        return self.image_ids.shape[0]"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"h3-oAySag_-n","executionInfo":{"status":"ok","timestamp":1680956855156,"user_tz":-330,"elapsed":12,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["def get_transform_train():\n","    return A.Compose([\n","        A.HorizontalFlip(p=0.5),\n","        A.RandomBrightnessContrast(p=0.2),\n","        ToTensorV2(p=1.0)\n","    ], bbox_params={'format':'pascal_voc', 'label_fields': ['labels']})\n","\n","def get_transform_valid():\n","    return A.Compose([\n","        ToTensorV2(p=1.0)\n","    ], bbox_params={'format': 'pascal_voc', 'label_fields':['labels']})"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1680956855156,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"cfWNyTMWg_-n","outputId":"6e6b0e1f-0e2c-44a5-e279-b30abb76d09a"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["def collate_fn(batch):\n","    return tuple(zip(*batch))\n","\n","train_dataset = VOCDataset(train_df, IMG_PATH , get_transform_train())\n","valid_dataset = VOCDataset(valid_df, IMG_PATH, get_transform_valid())\n","\n","\n","# split the dataset in train and test set\n","indices = torch.randperm(len(train_dataset)).tolist()\n","\n","\n","train_data_loader = DataLoader(\n","    train_dataset,\n","    batch_size=4,\n","    shuffle=True,\n","    num_workers=4,\n","    collate_fn=collate_fn\n",")\n","\n","valid_data_loader = DataLoader(\n","    valid_dataset,\n","    batch_size=4,\n","    shuffle=False,\n","    num_workers=4,\n","    collate_fn=collate_fn\n",")"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"VV2IexHNg_-o","executionInfo":{"status":"ok","timestamp":1680956855157,"user_tz":-330,"elapsed":9,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1LAnOhEDCYugHIQJCyYtFNGa5Nt_b8LAN","height":1000},"id":"DIdYOvrkg_-o","outputId":"ffa7df2e-ff0f-4f09-9210-eead1760d0e8","executionInfo":{"status":"ok","timestamp":1680956894923,"user_tz":-330,"elapsed":39774,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["images, targets= next(iter(train_data_loader))\n","images = list(image.to(device) for image in images)\n","targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","plt.figure(figsize=(20,20))\n","for i, (image, target) in enumerate(zip(images, targets)):\n","    plt.subplot(2,2, i+1)\n","    boxes = targets[i]['boxes'].cpu().numpy().astype(np.int32)\n","    sample = images[i].permute(1,2,0).cpu().numpy()\n","    names = targets[i]['labels'].cpu().numpy().astype(np.int64)\n","    for i,box in enumerate(boxes):\n","        cv2.rectangle(sample,\n","                      (box[0], box[1]),\n","                      (box[2], box[3]),\n","                      (0, 0, 220), 2)\n","        cv2.putText(sample, classes[names[i]], (box[0],box[1]+15),cv2.FONT_HERSHEY_COMPLEX ,0.5,(0,220,0),1,cv2.LINE_AA)  \n","\n","    plt.axis('off')\n","    plt.imshow(sample)\n","    "]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":928,"status":"ok","timestamp":1680956895829,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"MZuDSLpIg_-p","outputId":"4e37b964-55ab-4999-e848-c070f04706db"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n","100%|██████████| 160M/160M [00:00<00:00, 248MB/s]\n"]}],"source":["# load a model; pre-trained on COCO\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"ovW_8cxmg_-p","executionInfo":{"status":"ok","timestamp":1680956895830,"user_tz":-330,"elapsed":12,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["num_classes = 12\n","\n","# get number of input features for the classifier\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","\n","# replace the pre-trained head with a new one\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"CavTpFzNg_-q","executionInfo":{"status":"ok","timestamp":1680956895830,"user_tz":-330,"elapsed":11,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["model.to(device)\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005, weight_decay=0.0005)\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6418,"status":"ok","timestamp":1680956902237,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"4JyxrgvJg_-q","outputId":"9efd0045-93a4-47ea-ea03-6ceb5de19f3d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n","  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-nrhsvw70\n","  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-nrhsvw70\n","  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.9/dist-packages (from pycocotools==2.0) (67.6.1)\n","Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.9/dist-packages (from pycocotools==2.0) (0.29.34)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from pycocotools==2.0) (3.7.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (23.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.0.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (8.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.22.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.11.0)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (5.12.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (4.39.3)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=2.1.0->pycocotools==2.0) (3.15.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0) (1.16.0)\n","Building wheels for collected packages: pycocotools\n","  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycocotools: filename=pycocotools-2.0-cp39-cp39-linux_x86_64.whl size=398004 sha256=f7c0d6084e3996425fe032991e5576f8fdc6bbf167cd9310479fb6865edd63a5\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-mccmxwra/wheels/13/c1/d6/a321055f7089f1a6af654fbf794536b196999f082a9cb68a37\n","Successfully built pycocotools\n","Installing collected packages: pycocotools\n","  Attempting uninstall: pycocotools\n","    Found existing installation: pycocotools 2.0.6\n","    Uninstalling pycocotools-2.0.6:\n","      Successfully uninstalled pycocotools-2.0.6\n","Successfully installed pycocotools-2.0\n"]}],"source":["!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3277,"status":"ok","timestamp":1680956909145,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"kKqulq9Lg_-r","outputId":"95f120e2-95b2-43d0-fcdd-565c3cccded8"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'vision' already exists and is not an empty directory.\n"]}],"source":["!git clone https://github.com/pytorch/vision.git\n","!cd vision;cp references/detection/utils.py ../;cp references/detection/transforms.py ../;cp references/detection/coco_eval.py ../;cp references/detection/engine.py ../;cp references/detection/coco_utils.py ../"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"VggsFCZ5g_-r","executionInfo":{"status":"ok","timestamp":1680956905878,"user_tz":-330,"elapsed":3644,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["from engine import train_one_epoch, evaluate\n","import utils"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":791611,"status":"ok","timestamp":1680957700752,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"K-Idxjreg_-r","outputId":"9189b832-236a-4c8b-a99d-9b3d5ace91fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: [0]  [  0/112]  eta: 0:39:43  lr: 0.000050  loss: 3.2817 (3.2817)  loss_classifier: 2.9986 (2.9986)  loss_box_reg: 0.0729 (0.0729)  loss_objectness: 0.1815 (0.1815)  loss_rpn_box_reg: 0.0287 (0.0287)  time: 21.2795  data: 7.5196  max mem: 4274\n","Epoch: [0]  [ 10/112]  eta: 0:05:32  lr: 0.000500  loss: 3.1579 (3.2335)  loss_classifier: 2.8297 (2.7879)  loss_box_reg: 0.0427 (0.0519)  loss_objectness: 0.1641 (0.2539)  loss_rpn_box_reg: 0.1194 (0.1399)  time: 3.2615  data: 0.8686  max mem: 4276\n","Epoch: [0]  [ 20/112]  eta: 0:03:40  lr: 0.000950  loss: 2.5344 (2.6361)  loss_classifier: 2.2192 (2.2011)  loss_box_reg: 0.0451 (0.0527)  loss_objectness: 0.1259 (0.2595)  loss_rpn_box_reg: 0.1194 (0.1228)  time: 1.4490  data: 0.1873  max mem: 4277\n","Epoch: [0]  [ 30/112]  eta: 0:02:46  lr: 0.001400  loss: 1.1618 (2.0274)  loss_classifier: 0.8175 (1.6233)  loss_box_reg: 0.0504 (0.0582)  loss_objectness: 0.1278 (0.2416)  loss_rpn_box_reg: 0.0444 (0.1043)  time: 1.3539  data: 0.1533  max mem: 4277\n","Epoch: [0]  [ 40/112]  eta: 0:02:14  lr: 0.001850  loss: 0.5248 (1.6476)  loss_classifier: 0.2303 (1.2689)  loss_box_reg: 0.0396 (0.0559)  loss_objectness: 0.1478 (0.2208)  loss_rpn_box_reg: 0.0440 (0.1021)  time: 1.3174  data: 0.1431  max mem: 4277\n","Epoch: [0]  [ 50/112]  eta: 0:01:49  lr: 0.002300  loss: 0.4207 (1.4064)  loss_classifier: 0.1509 (1.0469)  loss_box_reg: 0.0307 (0.0546)  loss_objectness: 0.1267 (0.2086)  loss_rpn_box_reg: 0.0535 (0.0964)  time: 1.3555  data: 0.1525  max mem: 4277\n","Epoch: [0]  [ 60/112]  eta: 0:01:28  lr: 0.002750  loss: 0.3700 (1.2405)  loss_classifier: 0.1172 (0.8988)  loss_box_reg: 0.0348 (0.0546)  loss_objectness: 0.1038 (0.1979)  loss_rpn_box_reg: 0.0518 (0.0892)  time: 1.3462  data: 0.1409  max mem: 4277\n","Epoch: [0]  [ 70/112]  eta: 0:01:09  lr: 0.003200  loss: 0.3105 (1.1185)  loss_classifier: 0.1179 (0.7916)  loss_box_reg: 0.0465 (0.0545)  loss_objectness: 0.1069 (0.1879)  loss_rpn_box_reg: 0.0275 (0.0844)  time: 1.3377  data: 0.1281  max mem: 4277\n","Epoch: [0]  [ 80/112]  eta: 0:00:51  lr: 0.003650  loss: 0.3105 (1.0274)  loss_classifier: 0.1179 (0.7114)  loss_box_reg: 0.0477 (0.0552)  loss_objectness: 0.1069 (0.1776)  loss_rpn_box_reg: 0.0479 (0.0832)  time: 1.3423  data: 0.1382  max mem: 4278\n","Epoch: [0]  [ 90/112]  eta: 0:00:34  lr: 0.004100  loss: 0.3094 (0.9537)  loss_classifier: 0.1084 (0.6452)  loss_box_reg: 0.0424 (0.0542)  loss_objectness: 0.1024 (0.1719)  loss_rpn_box_reg: 0.0523 (0.0824)  time: 1.3176  data: 0.1469  max mem: 4278\n","Epoch: [0]  [100/112]  eta: 0:00:18  lr: 0.004550  loss: 0.3094 (0.8953)  loss_classifier: 0.0975 (0.5947)  loss_box_reg: 0.0468 (0.0552)  loss_objectness: 0.0960 (0.1650)  loss_rpn_box_reg: 0.0512 (0.0804)  time: 1.3260  data: 0.1514  max mem: 4278\n","Epoch: [0]  [110/112]  eta: 0:00:03  lr: 0.005000  loss: 0.3617 (0.8506)  loss_classifier: 0.1007 (0.5496)  loss_box_reg: 0.0468 (0.0539)  loss_objectness: 0.0988 (0.1642)  loss_rpn_box_reg: 0.0547 (0.0829)  time: 1.2976  data: 0.1273  max mem: 4278\n","Epoch: [0]  [111/112]  eta: 0:00:01  lr: 0.005000  loss: 0.3617 (0.8455)  loss_classifier: 0.1007 (0.5455)  loss_box_reg: 0.0468 (0.0538)  loss_objectness: 0.0988 (0.1633)  loss_rpn_box_reg: 0.0562 (0.0829)  time: 1.2316  data: 0.1159  max mem: 4278\n","Epoch: [0] Total time: 0:02:49 (1.5141 s / it)\n","creating index...\n","index created!\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Test:  [0/1]  eta: 0:00:02  model_time: 0.4757 (0.4757)  evaluator_time: 0.0056 (0.0056)  time: 2.3155  data: 1.7958  max mem: 4278\n","Test: Total time: 0:00:02 (2.4662 s / it)\n","Averaged stats: model_time: 0.4757 (0.4757)  evaluator_time: 0.0056 (0.0056)\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n","IoU metric: bbox\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","Epoch: [1]  [  0/112]  eta: 0:10:29  lr: 0.005000  loss: 0.2832 (0.2832)  loss_classifier: 0.1097 (0.1097)  loss_box_reg: 0.0479 (0.0479)  loss_objectness: 0.0855 (0.0855)  loss_rpn_box_reg: 0.0401 (0.0401)  time: 5.6221  data: 4.2697  max mem: 4278\n","Epoch: [1]  [ 10/112]  eta: 0:03:13  lr: 0.005000  loss: 0.2875 (0.3402)  loss_classifier: 0.0838 (0.1129)  loss_box_reg: 0.0379 (0.0544)  loss_objectness: 0.0761 (0.0904)  loss_rpn_box_reg: 0.0814 (0.0824)  time: 1.8951  data: 0.5497  max mem: 4278\n","Epoch: [1]  [ 20/112]  eta: 0:02:31  lr: 0.005000  loss: 0.3084 (0.3446)  loss_classifier: 0.0838 (0.1079)  loss_box_reg: 0.0379 (0.0512)  loss_objectness: 0.0828 (0.0949)  loss_rpn_box_reg: 0.0903 (0.0906)  time: 1.4431  data: 0.1623  max mem: 4278\n","Epoch: [1]  [ 30/112]  eta: 0:02:06  lr: 0.005000  loss: 0.3053 (0.3343)  loss_classifier: 0.1003 (0.1113)  loss_box_reg: 0.0412 (0.0544)  loss_objectness: 0.0951 (0.0935)  loss_rpn_box_reg: 0.0653 (0.0751)  time: 1.3448  data: 0.1377  max mem: 4278\n","Epoch: [1]  [ 40/112]  eta: 0:01:46  lr: 0.005000  loss: 0.2944 (0.3295)  loss_classifier: 0.0957 (0.1092)  loss_box_reg: 0.0405 (0.0546)  loss_objectness: 0.0864 (0.0945)  loss_rpn_box_reg: 0.0385 (0.0711)  time: 1.3030  data: 0.1180  max mem: 4278\n","Epoch: [1]  [ 50/112]  eta: 0:01:28  lr: 0.005000  loss: 0.3072 (0.3241)  loss_classifier: 0.0816 (0.1066)  loss_box_reg: 0.0357 (0.0539)  loss_objectness: 0.0950 (0.0942)  loss_rpn_box_reg: 0.0385 (0.0694)  time: 1.2548  data: 0.1042  max mem: 4278\n","Epoch: [1]  [ 60/112]  eta: 0:01:13  lr: 0.005000  loss: 0.2958 (0.3182)  loss_classifier: 0.0816 (0.1057)  loss_box_reg: 0.0424 (0.0544)  loss_objectness: 0.0757 (0.0914)  loss_rpn_box_reg: 0.0515 (0.0668)  time: 1.2933  data: 0.1343  max mem: 4278\n","Epoch: [1]  [ 70/112]  eta: 0:00:58  lr: 0.005000  loss: 0.2958 (0.3214)  loss_classifier: 0.1052 (0.1065)  loss_box_reg: 0.0572 (0.0555)  loss_objectness: 0.0748 (0.0924)  loss_rpn_box_reg: 0.0515 (0.0670)  time: 1.3402  data: 0.1465  max mem: 4278\n","Epoch: [1]  [ 80/112]  eta: 0:00:44  lr: 0.005000  loss: 0.3298 (0.3241)  loss_classifier: 0.1138 (0.1094)  loss_box_reg: 0.0699 (0.0585)  loss_objectness: 0.0748 (0.0910)  loss_rpn_box_reg: 0.0558 (0.0652)  time: 1.3376  data: 0.1305  max mem: 4278\n","Epoch: [1]  [ 90/112]  eta: 0:00:30  lr: 0.005000  loss: 0.3298 (0.3351)  loss_classifier: 0.1211 (0.1138)  loss_box_reg: 0.0749 (0.0635)  loss_objectness: 0.0769 (0.0913)  loss_rpn_box_reg: 0.0558 (0.0666)  time: 1.3368  data: 0.1374  max mem: 4278\n","Epoch: [1]  [100/112]  eta: 0:00:16  lr: 0.005000  loss: 0.3154 (0.3304)  loss_classifier: 0.1126 (0.1115)  loss_box_reg: 0.0594 (0.0618)  loss_objectness: 0.0722 (0.0895)  loss_rpn_box_reg: 0.0729 (0.0677)  time: 1.3226  data: 0.1341  max mem: 4278\n","Epoch: [1]  [110/112]  eta: 0:00:02  lr: 0.005000  loss: 0.2896 (0.3335)  loss_classifier: 0.0920 (0.1129)  loss_box_reg: 0.0525 (0.0640)  loss_objectness: 0.0703 (0.0881)  loss_rpn_box_reg: 0.0509 (0.0684)  time: 1.2033  data: 0.0927  max mem: 4278\n","Epoch: [1]  [111/112]  eta: 0:00:01  lr: 0.005000  loss: 0.2852 (0.3329)  loss_classifier: 0.0947 (0.1132)  loss_box_reg: 0.0538 (0.0642)  loss_objectness: 0.0679 (0.0877)  loss_rpn_box_reg: 0.0412 (0.0678)  time: 1.1540  data: 0.0876  max mem: 4278\n","Epoch: [1] Total time: 0:02:31 (1.3483 s / it)\n","creating index...\n","index created!\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Test:  [0/1]  eta: 0:00:01  model_time: 0.4808 (0.4808)  evaluator_time: 0.0093 (0.0093)  time: 1.9971  data: 1.4667  max mem: 4278\n","Test: Total time: 0:00:02 (2.1456 s / it)\n","Averaged stats: model_time: 0.4808 (0.4808)  evaluator_time: 0.0093 (0.0093)\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n","IoU metric: bbox\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","Epoch: [2]  [  0/112]  eta: 0:10:35  lr: 0.005000  loss: 0.2866 (0.2866)  loss_classifier: 0.0551 (0.0551)  loss_box_reg: 0.0122 (0.0122)  loss_objectness: 0.0944 (0.0944)  loss_rpn_box_reg: 0.1249 (0.1249)  time: 5.6727  data: 4.2802  max mem: 4278\n","Epoch: [2]  [ 10/112]  eta: 0:03:08  lr: 0.005000  loss: 0.2866 (0.3215)  loss_classifier: 0.1086 (0.1079)  loss_box_reg: 0.0694 (0.0685)  loss_objectness: 0.0837 (0.0898)  loss_rpn_box_reg: 0.0397 (0.0553)  time: 1.8490  data: 0.5480  max mem: 4278\n","Epoch: [2]  [ 20/112]  eta: 0:02:27  lr: 0.005000  loss: 0.2806 (0.3097)  loss_classifier: 0.1071 (0.1019)  loss_box_reg: 0.0557 (0.0636)  loss_objectness: 0.0645 (0.0776)  loss_rpn_box_reg: 0.0428 (0.0667)  time: 1.4049  data: 0.1593  max mem: 4278\n","Epoch: [2]  [ 30/112]  eta: 0:02:05  lr: 0.005000  loss: 0.2806 (0.3024)  loss_classifier: 0.0810 (0.1002)  loss_box_reg: 0.0499 (0.0646)  loss_objectness: 0.0634 (0.0740)  loss_rpn_box_reg: 0.0428 (0.0636)  time: 1.3558  data: 0.1538  max mem: 4278\n","Epoch: [2]  [ 40/112]  eta: 0:01:46  lr: 0.005000  loss: 0.2854 (0.3177)  loss_classifier: 0.0838 (0.1059)  loss_box_reg: 0.0499 (0.0697)  loss_objectness: 0.0722 (0.0762)  loss_rpn_box_reg: 0.0375 (0.0660)  time: 1.3571  data: 0.1493  max mem: 4278\n","Epoch: [2]  [ 50/112]  eta: 0:01:29  lr: 0.005000  loss: 0.2998 (0.3233)  loss_classifier: 0.0948 (0.1099)  loss_box_reg: 0.0556 (0.0747)  loss_objectness: 0.0796 (0.0746)  loss_rpn_box_reg: 0.0430 (0.0641)  time: 1.2955  data: 0.1296  max mem: 4278\n","Epoch: [2]  [ 60/112]  eta: 0:01:13  lr: 0.005000  loss: 0.2915 (0.3205)  loss_classifier: 0.0964 (0.1090)  loss_box_reg: 0.0712 (0.0741)  loss_objectness: 0.0706 (0.0751)  loss_rpn_box_reg: 0.0393 (0.0625)  time: 1.2660  data: 0.1240  max mem: 4278\n","Epoch: [2]  [ 70/112]  eta: 0:00:58  lr: 0.005000  loss: 0.2462 (0.3156)  loss_classifier: 0.0964 (0.1081)  loss_box_reg: 0.0540 (0.0731)  loss_objectness: 0.0646 (0.0730)  loss_rpn_box_reg: 0.0393 (0.0615)  time: 1.3089  data: 0.1239  max mem: 4278\n","Epoch: [2]  [ 80/112]  eta: 0:00:44  lr: 0.005000  loss: 0.2868 (0.3177)  loss_classifier: 0.1098 (0.1121)  loss_box_reg: 0.0663 (0.0768)  loss_objectness: 0.0537 (0.0702)  loss_rpn_box_reg: 0.0333 (0.0586)  time: 1.3153  data: 0.1239  max mem: 4278\n","Epoch: [2]  [ 90/112]  eta: 0:00:30  lr: 0.005000  loss: 0.3062 (0.3155)  loss_classifier: 0.1220 (0.1110)  loss_box_reg: 0.0745 (0.0760)  loss_objectness: 0.0537 (0.0696)  loss_rpn_box_reg: 0.0305 (0.0590)  time: 1.3121  data: 0.1312  max mem: 4278\n","Epoch: [2]  [100/112]  eta: 0:00:16  lr: 0.005000  loss: 0.3257 (0.3187)  loss_classifier: 0.1042 (0.1120)  loss_box_reg: 0.0745 (0.0771)  loss_objectness: 0.0669 (0.0705)  loss_rpn_box_reg: 0.0552 (0.0592)  time: 1.3191  data: 0.1404  max mem: 4278\n","Epoch: [2]  [110/112]  eta: 0:00:02  lr: 0.005000  loss: 0.3257 (0.3213)  loss_classifier: 0.1099 (0.1117)  loss_box_reg: 0.0764 (0.0769)  loss_objectness: 0.0797 (0.0717)  loss_rpn_box_reg: 0.0553 (0.0609)  time: 1.2066  data: 0.1021  max mem: 4279\n","Epoch: [2]  [111/112]  eta: 0:00:01  lr: 0.005000  loss: 0.3257 (0.3211)  loss_classifier: 0.1099 (0.1112)  loss_box_reg: 0.0764 (0.0762)  loss_objectness: 0.0797 (0.0730)  loss_rpn_box_reg: 0.0553 (0.0606)  time: 1.1551  data: 0.0960  max mem: 4279\n","Epoch: [2] Total time: 0:02:30 (1.3438 s / it)\n","creating index...\n","index created!\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Test:  [0/1]  eta: 0:00:01  model_time: 0.4521 (0.4521)  evaluator_time: 0.0111 (0.0111)  time: 1.7837  data: 1.2820  max mem: 4279\n","Test: Total time: 0:00:01 (1.9215 s / it)\n","Averaged stats: model_time: 0.4521 (0.4521)  evaluator_time: 0.0111 (0.0111)\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n","IoU metric: bbox\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.005\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.018\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.081\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.260\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","Epoch: [3]  [  0/112]  eta: 0:11:00  lr: 0.005000  loss: 0.3509 (0.3509)  loss_classifier: 0.1173 (0.1173)  loss_box_reg: 0.0824 (0.0824)  loss_objectness: 0.0950 (0.0950)  loss_rpn_box_reg: 0.0562 (0.0562)  time: 5.8948  data: 4.4573  max mem: 4279\n","Epoch: [3]  [ 10/112]  eta: 0:03:11  lr: 0.005000  loss: 0.3509 (0.3488)  loss_classifier: 0.1266 (0.1317)  loss_box_reg: 0.0966 (0.0954)  loss_objectness: 0.0599 (0.0610)  loss_rpn_box_reg: 0.0562 (0.0608)  time: 1.8754  data: 0.5643  max mem: 4279\n","Epoch: [3]  [ 20/112]  eta: 0:02:27  lr: 0.005000  loss: 0.2965 (0.3200)  loss_classifier: 0.1049 (0.1177)  loss_box_reg: 0.0650 (0.0820)  loss_objectness: 0.0590 (0.0617)  loss_rpn_box_reg: 0.0310 (0.0587)  time: 1.3873  data: 0.1454  max mem: 4279\n","Epoch: [3]  [ 30/112]  eta: 0:02:04  lr: 0.005000  loss: 0.2360 (0.3151)  loss_classifier: 0.0966 (0.1166)  loss_box_reg: 0.0650 (0.0838)  loss_objectness: 0.0540 (0.0592)  loss_rpn_box_reg: 0.0335 (0.0555)  time: 1.3210  data: 0.1336  max mem: 4279\n","Epoch: [3]  [ 40/112]  eta: 0:01:46  lr: 0.005000  loss: 0.3146 (0.3221)  loss_classifier: 0.1168 (0.1172)  loss_box_reg: 0.0918 (0.0866)  loss_objectness: 0.0532 (0.0601)  loss_rpn_box_reg: 0.0586 (0.0581)  time: 1.3469  data: 0.1503  max mem: 4279\n","Epoch: [3]  [ 50/112]  eta: 0:01:29  lr: 0.005000  loss: 0.3146 (0.3231)  loss_classifier: 0.1092 (0.1156)  loss_box_reg: 0.0907 (0.0856)  loss_objectness: 0.0630 (0.0616)  loss_rpn_box_reg: 0.0589 (0.0602)  time: 1.3226  data: 0.1359  max mem: 4279\n","Epoch: [3]  [ 60/112]  eta: 0:01:13  lr: 0.005000  loss: 0.3053 (0.3220)  loss_classifier: 0.1054 (0.1142)  loss_box_reg: 0.0735 (0.0853)  loss_objectness: 0.0534 (0.0604)  loss_rpn_box_reg: 0.0660 (0.0621)  time: 1.2637  data: 0.1164  max mem: 4279\n","Epoch: [3]  [ 70/112]  eta: 0:00:58  lr: 0.005000  loss: 0.2897 (0.3155)  loss_classifier: 0.0875 (0.1087)  loss_box_reg: 0.0620 (0.0795)  loss_objectness: 0.0561 (0.0624)  loss_rpn_box_reg: 0.0711 (0.0649)  time: 1.2722  data: 0.1263  max mem: 4279\n","Epoch: [3]  [ 80/112]  eta: 0:00:44  lr: 0.005000  loss: 0.2897 (0.3183)  loss_classifier: 0.0873 (0.1108)  loss_box_reg: 0.0476 (0.0810)  loss_objectness: 0.0714 (0.0645)  loss_rpn_box_reg: 0.0522 (0.0619)  time: 1.3104  data: 0.1416  max mem: 4279\n","Epoch: [3]  [ 90/112]  eta: 0:00:30  lr: 0.005000  loss: 0.3053 (0.3166)  loss_classifier: 0.0929 (0.1104)  loss_box_reg: 0.0642 (0.0810)  loss_objectness: 0.0688 (0.0646)  loss_rpn_box_reg: 0.0377 (0.0605)  time: 1.3146  data: 0.1379  max mem: 4279\n","Epoch: [3]  [100/112]  eta: 0:00:16  lr: 0.005000  loss: 0.3044 (0.3198)  loss_classifier: 0.0929 (0.1118)  loss_box_reg: 0.0581 (0.0826)  loss_objectness: 0.0629 (0.0655)  loss_rpn_box_reg: 0.0413 (0.0599)  time: 1.3303  data: 0.1402  max mem: 4279\n","Epoch: [3]  [110/112]  eta: 0:00:02  lr: 0.005000  loss: 0.2795 (0.3176)  loss_classifier: 0.0951 (0.1114)  loss_box_reg: 0.0682 (0.0826)  loss_objectness: 0.0604 (0.0654)  loss_rpn_box_reg: 0.0413 (0.0583)  time: 1.2175  data: 0.1028  max mem: 4279\n","Epoch: [3]  [111/112]  eta: 0:00:01  lr: 0.005000  loss: 0.2718 (0.3164)  loss_classifier: 0.0951 (0.1113)  loss_box_reg: 0.0672 (0.0823)  loss_objectness: 0.0604 (0.0650)  loss_rpn_box_reg: 0.0365 (0.0578)  time: 1.1672  data: 0.0992  max mem: 4279\n","Epoch: [3] Total time: 0:02:30 (1.3409 s / it)\n","creating index...\n","index created!\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Test:  [0/1]  eta: 0:00:01  model_time: 0.4517 (0.4517)  evaluator_time: 0.0137 (0.0137)  time: 1.7538  data: 1.2493  max mem: 4279\n","Test: Total time: 0:00:01 (1.8916 s / it)\n","Averaged stats: model_time: 0.4517 (0.4517)  evaluator_time: 0.0137 (0.0137)\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n","IoU metric: bbox\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.005\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.069\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.220\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","Epoch: [4]  [  0/112]  eta: 0:07:40  lr: 0.005000  loss: 0.3396 (0.3396)  loss_classifier: 0.1552 (0.1552)  loss_box_reg: 0.1176 (0.1176)  loss_objectness: 0.0477 (0.0477)  loss_rpn_box_reg: 0.0192 (0.0192)  time: 4.1099  data: 2.7855  max mem: 4279\n","Epoch: [4]  [ 10/112]  eta: 0:03:08  lr: 0.005000  loss: 0.3287 (0.3043)  loss_classifier: 0.1002 (0.1101)  loss_box_reg: 0.0834 (0.0846)  loss_objectness: 0.0574 (0.0542)  loss_rpn_box_reg: 0.0537 (0.0553)  time: 1.8521  data: 0.5059  max mem: 4279\n","Epoch: [4]  [ 20/112]  eta: 0:02:29  lr: 0.005000  loss: 0.3178 (0.3311)  loss_classifier: 0.1007 (0.1194)  loss_box_reg: 0.0834 (0.0924)  loss_objectness: 0.0574 (0.0632)  loss_rpn_box_reg: 0.0421 (0.0560)  time: 1.4990  data: 0.2146  max mem: 4279\n","Epoch: [4]  [ 30/112]  eta: 0:02:05  lr: 0.005000  loss: 0.2871 (0.3280)  loss_classifier: 0.1057 (0.1203)  loss_box_reg: 0.0844 (0.0937)  loss_objectness: 0.0549 (0.0609)  loss_rpn_box_reg: 0.0363 (0.0532)  time: 1.3545  data: 0.1522  max mem: 4279\n","Epoch: [4]  [ 40/112]  eta: 0:01:47  lr: 0.005000  loss: 0.2859 (0.3192)  loss_classifier: 0.1007 (0.1160)  loss_box_reg: 0.0711 (0.0904)  loss_objectness: 0.0557 (0.0592)  loss_rpn_box_reg: 0.0523 (0.0536)  time: 1.3522  data: 0.1539  max mem: 4279\n","Epoch: [4]  [ 50/112]  eta: 0:01:29  lr: 0.005000  loss: 0.2859 (0.3130)  loss_classifier: 0.0955 (0.1128)  loss_box_reg: 0.0626 (0.0865)  loss_objectness: 0.0557 (0.0585)  loss_rpn_box_reg: 0.0623 (0.0552)  time: 1.3244  data: 0.1366  max mem: 4279\n","Epoch: [4]  [ 60/112]  eta: 0:01:14  lr: 0.005000  loss: 0.2857 (0.3124)  loss_classifier: 0.1060 (0.1145)  loss_box_reg: 0.0685 (0.0895)  loss_objectness: 0.0545 (0.0570)  loss_rpn_box_reg: 0.0341 (0.0514)  time: 1.2842  data: 0.1199  max mem: 4279\n","Epoch: [4]  [ 70/112]  eta: 0:00:59  lr: 0.005000  loss: 0.2857 (0.3118)  loss_classifier: 0.1095 (0.1140)  loss_box_reg: 0.0933 (0.0887)  loss_objectness: 0.0514 (0.0561)  loss_rpn_box_reg: 0.0281 (0.0530)  time: 1.2985  data: 0.1300  max mem: 4279\n","Epoch: [4]  [ 80/112]  eta: 0:00:44  lr: 0.005000  loss: 0.2938 (0.3129)  loss_classifier: 0.1110 (0.1157)  loss_box_reg: 0.0960 (0.0910)  loss_objectness: 0.0421 (0.0550)  loss_rpn_box_reg: 0.0319 (0.0512)  time: 1.3347  data: 0.1368  max mem: 4279\n","Epoch: [4]  [ 90/112]  eta: 0:00:30  lr: 0.005000  loss: 0.2976 (0.3174)  loss_classifier: 0.1110 (0.1155)  loss_box_reg: 0.0960 (0.0914)  loss_objectness: 0.0458 (0.0549)  loss_rpn_box_reg: 0.0672 (0.0556)  time: 1.3448  data: 0.1375  max mem: 4279\n","Epoch: [4]  [100/112]  eta: 0:00:16  lr: 0.005000  loss: 0.2727 (0.3124)  loss_classifier: 0.0938 (0.1146)  loss_box_reg: 0.0641 (0.0894)  loss_objectness: 0.0462 (0.0546)  loss_rpn_box_reg: 0.0611 (0.0537)  time: 1.3287  data: 0.1396  max mem: 4279\n","Epoch: [4]  [110/112]  eta: 0:00:02  lr: 0.005000  loss: 0.2450 (0.3075)  loss_classifier: 0.0795 (0.1116)  loss_box_reg: 0.0530 (0.0868)  loss_objectness: 0.0518 (0.0556)  loss_rpn_box_reg: 0.0338 (0.0534)  time: 1.2091  data: 0.1008  max mem: 4279\n","Epoch: [4]  [111/112]  eta: 0:00:01  lr: 0.005000  loss: 0.2385 (0.3056)  loss_classifier: 0.0772 (0.1111)  loss_box_reg: 0.0530 (0.0862)  loss_objectness: 0.0518 (0.0552)  loss_rpn_box_reg: 0.0327 (0.0531)  time: 1.1597  data: 0.0968  max mem: 4279\n","Epoch: [4] Total time: 0:02:31 (1.3524 s / it)\n","creating index...\n","index created!\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Test:  [0/1]  eta: 0:00:01  model_time: 0.4571 (0.4571)  evaluator_time: 0.0103 (0.0103)  time: 1.7627  data: 1.2568  max mem: 4279\n","Test: Total time: 0:00:01 (1.9069 s / it)\n","Averaged stats: model_time: 0.4571 (0.4571)  evaluator_time: 0.0103 (0.0103)\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n","IoU metric: bbox\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.013\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.032\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.010\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.062\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.113\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.062\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.160\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","CPU times: user 5min 8s, sys: 33.1 s, total: 5min 41s\n","Wall time: 13min 12s\n"]}],"source":["%%time\n","# let's train it for 1 epoch\n","num_epochs = 5\n","\n","for epoch in range(num_epochs):\n","    # train for one epoch, printing every 10 iterations\n","    train_one_epoch(model, optimizer, train_data_loader, device, epoch, print_freq=10)\n","    # update the learning rate\n","    lr_scheduler.step()\n","    # evaluate on the test dataset\n","    evaluate(model, valid_data_loader, device=device)"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"M8oQFNLMg_-s","executionInfo":{"status":"ok","timestamp":1680957726875,"user_tz":-330,"elapsed":2453,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["torch.save(model.state_dict(), 'faster_rcnn_state3.pth')"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":694,"status":"ok","timestamp":1680957727565,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"b-G2lTWRg_-s","outputId":"57c77537-bc3c-4bbb-ca34-397cd9135395"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained_backbone' is deprecated since 0.13 and may be removed in the future, please use 'weights_backbone' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights_backbone' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights_backbone=None`.\n","  warnings.warn(msg)\n"]}],"source":["# load  a model; pre-trained on COCO\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, pretrained_backbone=False)\n","\n","WEIGHTS_FILE = \"./faster_rcnn_state3.pth\"\n","\n","num_classes = 12\n","\n","# get number of input features for the classifier\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","\n","# replace the pre-trained head with a new one\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","# Load the traines weights\n","model.load_state_dict(torch.load(WEIGHTS_FILE))\n","\n","model = model.to(device)\n"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"ISQInM55g_-t","executionInfo":{"status":"ok","timestamp":1680957728868,"user_tz":-330,"elapsed":3,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["def obj_detector(img):\n","    img = cv2.imread(img, cv2.IMREAD_COLOR)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n","\n","\n","    img /= 255.0\n","    img = torch.from_numpy(img)\n","    img = img.unsqueeze(0)\n","    img = img.permute(0,3,1,2)\n","    \n","    model.eval()\n","\n","    detection_threshold = 0.70\n","    \n","    img = list(im.to(device) for im in img)\n","    output = model(img)\n","\n","    for i , im in enumerate(img):\n","        boxes = output[i]['boxes'].data.cpu().numpy()\n","        scores = output[i]['scores'].data.cpu().numpy()\n","        labels = output[i]['labels'].data.cpu().numpy()\n","\n","        labels = labels[scores >= detection_threshold]\n","        boxes = boxes[scores >= detection_threshold].astype(np.int32)\n","        scores = scores[scores >= detection_threshold]\n","\n","        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n","        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n","    \n","    sample = img[0].permute(1,2,0).cpu().numpy()\n","    sample = np.array(sample)\n","    boxes = output[0]['boxes'].data.cpu().numpy()\n","    name = output[0]['labels'].data.cpu().numpy()\n","    scores = output[0]['scores'].data.cpu().numpy()\n","    boxes = boxes[scores >= detection_threshold].astype(np.int32)\n","    names = name.tolist()\n","    \n","    return names, boxes, sample"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37173,"status":"ok","timestamp":1680957795075,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"rlpYQbaDg_-t","outputId":"d3900817-c8c3-43b9-e3da-1bebf0d84295"},"outputs":[{"output_type":"stream","name":"stdout","text":["0 ./test3/0000007_05999_d_0000038.jpg\n","1 ./test3/0000002_00005_d_0000014.jpg\n","2 ./test3/0000072_00000_d_0000001.jpg\n","3 ./test3/0000107_02196_d_0000055.jpg\n","4 ./test3/0000072_07660_d_0000012.jpg\n","5 ./test3/0000008_00889_d_0000039.jpg\n","6 ./test3/0000008_03499_d_0000043.jpg\n","7 ./test3/0000008_03999_d_0000044.jpg\n","8 ./test3/0000008_04499_d_0000045.jpg\n","9 ./test3/0000008_02999_d_0000042.jpg\n","10 ./test3/0000008_02499_d_0000041.jpg\n","11 ./test3/0000008_01999_d_0000040.jpg\n","12 ./test3/0000036_00500_d_0000046.jpg\n","13 ./test3/0000031_02000_d_0000041.jpg\n","14 ./test3/0000031_03527_d_0000043.jpg\n","15 ./test3/0000031_00000_d_0000037.jpg\n","16 ./test3/9999999_00301_d_0000133.jpg\n","17 ./test3/9999999_00299_d_0000132.jpg\n","18 ./test3/0000040_04284_d_0000071.jpg\n","19 ./test3/0000040_02454_d_0000068.jpg\n","20 ./test3/0000040_03288_d_0000069.jpg\n","21 ./test3/0000040_03752_d_0000070.jpg\n","22 ./test3/0000040_01500_d_0000067.jpg\n","23 ./test3/0000040_01000_d_0000066.jpg\n","24 ./test3/0000039_05300_d_0000061.jpg\n","25 ./test3/0000039_00000_d_0000055.jpg\n","26 ./test3/0000037_01494_d_0000052.jpg\n","27 ./test3/0000039_05625_d_0000062.jpg\n","28 ./test3/0000036_03591_d_0000048.jpg\n","29 ./test3/9999999_00330_d_0000144.jpg\n","30 ./test3/9999999_00332_d_0000145.jpg\n","31 ./test3/9999999_00328_d_0000143.jpg\n","32 ./test3/9999999_00326_d_0000142.jpg\n","33 ./test3/9999999_00322_d_0000141.jpg\n","34 ./test3/9999999_00320_d_0000140.jpg\n","35 ./test3/9999999_00318_d_0000139.jpg\n","36 ./test3/9999999_00313_d_0000138.jpg\n","37 ./test3/9999999_00309_d_0000137.jpg\n","38 ./test3/9999999_00307_d_0000136.jpg\n","39 ./test3/9999999_00303_d_0000134.jpg\n","40 ./test3/9999999_00305_d_0000135.jpg\n","41 ./test3/9999999_00354_d_0000154.jpg\n","42 ./test3/9999999_00356_d_0000155.jpg\n","43 ./test3/9999999_00348_d_0000153.jpg\n","44 ./test3/9999999_00346_d_0000152.jpg\n","45 ./test3/9999999_00342_d_0000150.jpg\n","46 ./test3/9999999_00344_d_0000151.jpg\n","47 ./test3/9999999_00340_d_0000149.jpg\n","48 ./test3/9999999_00338_d_0000148.jpg\n","49 ./test3/9999999_00336_d_0000147.jpg\n"]}],"source":["pred_path = \"./test3\"\n","pred_files = [os.path.join(pred_path,f) for f in os.listdir(pred_path)]\n","\n","for i, images in enumerate(pred_files):\n","    print(i,images)\n","    names,boxes,sample = obj_detector(images)\n","\n","    img = cv2.imread(images)\n","    \n","    for i,box in enumerate(boxes):\n","        cv2.rectangle(img,\n","                      (box[0], box[1]),\n","                      (box[2], box[3]),\n","                      (0, 220, 0), 2)  \n","\n","    cv2.imwrite(f'./test4/{images[7:]}',img)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1V0y9Jo0CKCAU2vg6hy8V9vHxUauNk0lz","timestamp":1679820769372}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}