{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29393,"status":"ok","timestamp":1680954154141,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"AYTJICU8mTMX","outputId":"1fe187bd-8b4f-405d-f63c-1c503f47eb7c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":720,"status":"ok","timestamp":1680954154857,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"nKm2GBdCmU2s","outputId":"e1fb52c8-e002-4575-f0f8-8119cb4a1503"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/data_visualization/datavis_data\n"]}],"source":["cd /content/gdrive/MyDrive/data_visualization/datavis_data/"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":6353,"status":"ok","timestamp":1680954161207,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"lte9XrLRhFVx"},"outputs":[],"source":["import os\n","import collections\n","import pandas as pd\n","import numpy as np\n","import functools\n","import matplotlib.pyplot as plt\n","import cv2\n","\n","from sklearn import preprocessing \n","\n","\n","import xml.etree.ElementTree as ET\n","\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2\n","\n","import torch\n","import torchvision\n","\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection import FasterRCNN\n","from torchvision.models.detection.rpn import AnchorGenerator\n","\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.data import SequentialSampler"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25529,"status":"ok","timestamp":1680954186724,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"8oUILFDVg_-P","outputId":"fec48645-792c-4614-853c-c21b6ba4efa6"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{},"execution_count":4}],"source":["XML_PATH = \"annotation\"\n","IMG_PATH = \"train\"\n","XML_FILES = [os.path.join(XML_PATH, f) for f in os.listdir(XML_PATH)]\n","XML_FILES = XML_FILES[:1000] #first 1000\n","\n","len(XML_FILES)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"O_U86BV5g_-Z","executionInfo":{"status":"ok","timestamp":1680954186724,"user_tz":-330,"elapsed":5,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["class XmlParser(object):\n","\n","    def __init__(self,xml_file):\n","\n","        self.xml_file = self.filter(xml_file)\n","        \n","        # path to the image file = name of annotation file\n","        self.img_name = xml_file.split('/')[1].split('.')[0]+\".jpg\";\n","        self.img_path = os.path.join(IMG_PATH, self.img_name)\n","\n","        # image id \n","        self.image_id = self.img_name.split('.')[0];\n","\n","        # names of the classes contained in the xml file\n","        self.names = self._get_names()\n","        # coordinates of the bounding boxes\n","        self.boxes = self._get_bndbox()\n","\n","    def filter(self,xml_file):\n","\n","        filtered_data = []\n","\n","        f = open(xml_file, 'r')\n","\n","        for line in f:\n","            data = line.split(',')\n","            if data[5]!='0' and (data[5]=='5' or data[5]=='6'):\n","                data = [int(x.strip()) for x in data]\n","                filtered_data.append(data)\n","\n","                #augmentation for people\n","                if data[5]=='1' or data[5]=='2':\n","                  filtered_data.append(data)\n","\n","        return filtered_data\n","\n","    def _get_names(self):\n","\n","        label_dict = {\n","                      0 : \"Ignore\",\n","                      1 : \"Pedestrian\",\n","                      2 : \"People\",\n","                      3 : \"Bicycle\",\n","                      4 : \"Car\",\n","                      5 : \"Van\",\n","                      6 : \"Truck\",\n","                      7 : \"Tricycle\",\n","                      8 : \"Awning-tricycle\",\n","                      9 : \"Bus\",\n","                      10 : \"Motor\",\n","                      11 : \"Others\"\n","                    }\n","\n","        names = []\n","\n","        for data in self.xml_file:\n","              class_id = data[5]\n","              names.append(label_dict[class_id])\n","\n","        return np.array(names)\n","\n","    def _get_bndbox(self):\n","\n","        boxes = []\n","\n","        for data in self.xml_file:\n","            \n","            coordinates = []\n","            coordinates.append(np.int32(data[0])) #xmin\n","            coordinates.append(np.int32(np.float32(data[1]))) #ymin\n","            coordinates.append(np.int32(data[2]+data[0])) #xmax\n","            coordinates.append(np.int32(data[3]+data[1])) #ymax\n","            boxes.append(coordinates)\n","\n","        return np.array(boxes)\n","\n","# xml = XmlParser('Annotations/0000007_05999_d_0000038.txt')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":101742,"status":"ok","timestamp":1680954288462,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"_NvoeGhmi6Rh","outputId":"f49c434a-e614-4f9d-ae0f-b861b0e9fab5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["7048"]},"metadata":{},"execution_count":6}],"source":["def xml_files_to_df(xml_files):\n","    \n","    \"\"\"\"Return pandas dataframe from list of XML files.\"\"\"\n","    \n","    names = []\n","    boxes = []\n","    image_id = []\n","    xml_path = []\n","    img_path = []\n","    for file in xml_files:\n","        xml = XmlParser(file)\n","        names.extend(xml.names)\n","        boxes.extend(xml.boxes)\n","        image_id.extend([xml.image_id] * len(xml.names))\n","        xml_path.extend([xml.xml_file] * len(xml.names))\n","        img_path.extend([xml.img_path] * len(xml.names))\n","    a = {\"img_id\": image_id,\n","         \"names\": names,\n","         \"boxes\": boxes,\n","         \"xml_path\":xml_path,\n","         \"img_path\":img_path}\n","    \n","    df = pd.DataFrame.from_dict(a, orient='index')\n","    df = df.transpose()\n","    \n","    return df\n","\n","df = xml_files_to_df(XML_FILES)\n","df.head()\n","df.shape[0]"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1680954288462,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"UL91oDD4g_-c","outputId":"e8014904-4600-4a83-fd50-2f957c6db1c2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Van      5029\n","Truck    2019\n","Name: names, dtype: int64"]},"metadata":{},"execution_count":7}],"source":["# check values for per class\n","df['names'].value_counts()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1680954288464,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"Ui-v8WIHg_-d","outputId":"d606b3da-36d0-467b-fc06-15c9a4eaf090"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0        [745, 791, 818, 937]\n","1        [768, 683, 827, 792]\n","2        [730, 635, 780, 714]\n","3        [797, 526, 838, 583]\n","4        [808, 464, 838, 503]\n","                ...          \n","7043     [110, 149, 188, 182]\n","7044     [160, 194, 227, 219]\n","7045     [284, 177, 319, 198]\n","7046     [355, 145, 381, 169]\n","7047    [875, 333, 1075, 386]\n","Name: boxes, Length: 7048, dtype: object"]},"metadata":{},"execution_count":8}],"source":["df['boxes']"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1680954288464,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"D_sTTUxBg_-e","outputId":"9485253e-f27c-45c1-9eb2-f0b53a95f434"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py:3473: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  if (await self.run_code(code, result,  async_=asy)):\n"]}],"source":["# classes need to be in int form so we use LabelEncoder for this task\n","enc = preprocessing.LabelEncoder()\n","df['labels'] = enc.fit_transform(df['names'])\n","df['labels'] = np.stack(df['labels'][i]+1 for i in range(len(df['labels']))) "]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1680954288465,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"byc5kANsg_-f","outputId":"eaf4f0a1-299d-4962-953a-c6b7c1af7093"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["names  labels\n","Van    2         5029\n","Truck  1         2019\n","dtype: int64"]},"metadata":{},"execution_count":10}],"source":["classes = df[['names','labels']].value_counts()\n","classes"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1680954288465,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"9a-7b1bKsj89","outputId":"f2dae2d6-9b5c-4653-abf4-70448e013053"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                    img_id names                 boxes  \\\n","0  9999994_00000_d_0000055   Van  [745, 791, 818, 937]   \n","1  9999994_00000_d_0000055   Van  [768, 683, 827, 792]   \n","2  9999994_00000_d_0000055   Van  [730, 635, 780, 714]   \n","3  9999994_00000_d_0000055   Van  [797, 526, 838, 583]   \n","4  9999994_00000_d_0000055   Van  [808, 464, 838, 503]   \n","\n","                                            xml_path  \\\n","0  [[745, 791, 73, 146, 1, 5, 0, 0], [768, 683, 5...   \n","1  [[745, 791, 73, 146, 1, 5, 0, 0], [768, 683, 5...   \n","2  [[745, 791, 73, 146, 1, 5, 0, 0], [768, 683, 5...   \n","3  [[745, 791, 73, 146, 1, 5, 0, 0], [768, 683, 5...   \n","4  [[745, 791, 73, 146, 1, 5, 0, 0], [768, 683, 5...   \n","\n","                            img_path  labels  \n","0  train/9999994_00000_d_0000055.jpg       2  \n","1  train/9999994_00000_d_0000055.jpg       2  \n","2  train/9999994_00000_d_0000055.jpg       2  \n","3  train/9999994_00000_d_0000055.jpg       2  \n","4  train/9999994_00000_d_0000055.jpg       2  "],"text/html":["\n","  <div id=\"df-2d2f7587-5b12-448a-b964-21528eb87fa9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>img_id</th>\n","      <th>names</th>\n","      <th>boxes</th>\n","      <th>xml_path</th>\n","      <th>img_path</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>Van</td>\n","      <td>[745, 791, 818, 937]</td>\n","      <td>[[745, 791, 73, 146, 1, 5, 0, 0], [768, 683, 5...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>Van</td>\n","      <td>[768, 683, 827, 792]</td>\n","      <td>[[745, 791, 73, 146, 1, 5, 0, 0], [768, 683, 5...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>Van</td>\n","      <td>[730, 635, 780, 714]</td>\n","      <td>[[745, 791, 73, 146, 1, 5, 0, 0], [768, 683, 5...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>Van</td>\n","      <td>[797, 526, 838, 583]</td>\n","      <td>[[745, 791, 73, 146, 1, 5, 0, 0], [768, 683, 5...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>Van</td>\n","      <td>[808, 464, 838, 503]</td>\n","      <td>[[745, 791, 73, 146, 1, 5, 0, 0], [768, 683, 5...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d2f7587-5b12-448a-b964-21528eb87fa9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2d2f7587-5b12-448a-b964-21528eb87fa9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2d2f7587-5b12-448a-b964-21528eb87fa9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}],"source":["df.head()"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"ZPxyczp5g_-g","executionInfo":{"status":"ok","timestamp":1680954288466,"user_tz":-330,"elapsed":15,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["classes = {\n","                      1 : \"Van\",\n","                      2 : \"Truck\",\n","                    }"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1680954288466,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"NFVN1DODg_-h","outputId":"f45e18ab-4f4e-483a-d400-bfe163db407e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py:3473: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  if (await self.run_code(code, result,  async_=asy)):\n"]}],"source":["#bounding box coordinates point need to be in separate columns\n","\n","df['xmin'] = -1\n","df['ymin'] = -1\n","df['xmax'] = -1\n","df['ymax'] = -1\n","\n","df[['xmin','ymin','xmax','ymax']]=np.stack(df['boxes'][i] for i in range(len(df['boxes'])))\n","\n","df.drop(columns=['boxes'], inplace=True)\n","df['xmin'] = df['xmin'].astype(float)\n","df['ymin'] = df['ymin'].astype(float)\n","df['xmax'] = df['xmax'].astype(float)\n","df['ymax'] = df['ymax'].astype(float)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":915,"status":"ok","timestamp":1680954289370,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"OpjbwFXAg_-i","outputId":"7c4bb173-1c5f-4f92-ed96-9ae2778d4fd0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                    img_id                                           xml_path  \\\n","0  9999994_00000_d_0000055  [[745, 791, 73, 146, 1, 5, 0, 0], [768, 683, 5...   \n","1  9999994_00000_d_0000055  [[745, 791, 73, 146, 1, 5, 0, 0], [768, 683, 5...   \n","2  9999994_00000_d_0000055  [[745, 791, 73, 146, 1, 5, 0, 0], [768, 683, 5...   \n","3  9999994_00000_d_0000055  [[745, 791, 73, 146, 1, 5, 0, 0], [768, 683, 5...   \n","4  9999994_00000_d_0000055  [[745, 791, 73, 146, 1, 5, 0, 0], [768, 683, 5...   \n","\n","                            img_path  labels   xmin   ymin   xmax   ymax  \n","0  train/9999994_00000_d_0000055.jpg       2  745.0  791.0  818.0  937.0  \n","1  train/9999994_00000_d_0000055.jpg       2  768.0  683.0  827.0  792.0  \n","2  train/9999994_00000_d_0000055.jpg       2  730.0  635.0  780.0  714.0  \n","3  train/9999994_00000_d_0000055.jpg       2  797.0  526.0  838.0  583.0  \n","4  train/9999994_00000_d_0000055.jpg       2  808.0  464.0  838.0  503.0  "],"text/html":["\n","  <div id=\"df-040d5343-a8af-483e-b951-fb299ccf82e2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>img_id</th>\n","      <th>xml_path</th>\n","      <th>img_path</th>\n","      <th>labels</th>\n","      <th>xmin</th>\n","      <th>ymin</th>\n","      <th>xmax</th>\n","      <th>ymax</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>[[745, 791, 73, 146, 1, 5, 0, 0], [768, 683, 5...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","      <td>745.0</td>\n","      <td>791.0</td>\n","      <td>818.0</td>\n","      <td>937.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>[[745, 791, 73, 146, 1, 5, 0, 0], [768, 683, 5...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","      <td>768.0</td>\n","      <td>683.0</td>\n","      <td>827.0</td>\n","      <td>792.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>[[745, 791, 73, 146, 1, 5, 0, 0], [768, 683, 5...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","      <td>730.0</td>\n","      <td>635.0</td>\n","      <td>780.0</td>\n","      <td>714.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>[[745, 791, 73, 146, 1, 5, 0, 0], [768, 683, 5...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","      <td>797.0</td>\n","      <td>526.0</td>\n","      <td>838.0</td>\n","      <td>583.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>[[745, 791, 73, 146, 1, 5, 0, 0], [768, 683, 5...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","      <td>808.0</td>\n","      <td>464.0</td>\n","      <td>838.0</td>\n","      <td>503.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-040d5343-a8af-483e-b951-fb299ccf82e2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-040d5343-a8af-483e-b951-fb299ccf82e2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-040d5343-a8af-483e-b951-fb299ccf82e2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}],"source":["# drop names column since we dont need it anymore\n","df.drop(columns=['names'], inplace=True)\n","df.head()"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1680954289371,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"m7RqwLzZg_-j","outputId":"72fe5325-31a3-4133-adb3-8461bf9eea3b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["865"]},"metadata":{},"execution_count":15}],"source":["len(df['img_id'].unique())"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1680954289372,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"JYr0ORPlg_-j","outputId":"d53779b1-e8e7-4e6d-a95e-0425ba5aa035"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["861"]},"metadata":{},"execution_count":16}],"source":["image_ids = df['img_id'].unique()\n","valid_ids = image_ids[-4:]\n","train_ids = image_ids[:-4]\n","len(train_ids)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1680954289373,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"W96Vu4Hpg_-k","outputId":"b5e8397d-e736-427b-b5f5-324531334bee"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((26, 8), (7022, 8))"]},"metadata":{},"execution_count":17}],"source":["valid_df = df[df['img_id'].isin(valid_ids)]\n","train_df = df[df['img_id'].isin(train_ids)]\n","valid_df.shape, train_df.shape"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"EvCx_P7mg_-k","executionInfo":{"status":"ok","timestamp":1680954296183,"user_tz":-330,"elapsed":6820,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["!pip install -q albumentations\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import numpy as np\n","import os\n","from albumentations import RandomRotate90\n","from tensorflow.keras import mixed_precision\n","import gc"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"LX7lOczzg_-l","executionInfo":{"status":"ok","timestamp":1680954296184,"user_tz":-330,"elapsed":11,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["def func(image):\n","    Trgb2lms =np.array( [\n","          np.array([17.8824, 43.5161, 4.1194]),\n","          np.array([3.4557,27.1154, 3.8671]),\n","          np.array([0.0300, 0.1843, 1.4671]) \n","      ])\n","    \n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    x,y,z = image.shape\n","#     print(image.shape)\n","    cvd_due = np.array([\n","                     np.array([1 ,0, 0]),   \n","                     np.array([0.494207, 0, 1.24827]),   \n","                     np.array([0, 0, 1]),   \n","    ])\n","    INV_Trgb2lms = np.linalg.inv(Trgb2lms) \n","\n","#     print(image.transpose(2, 0, 1).shape)\n","    out = np.dot(INV_Trgb2lms, cvd_due)\n","    out = np.dot(out, Trgb2lms)\n","    out = np.dot(out, image.transpose(2, 0, 1).reshape(3,-1)) \n","    out = out.reshape(3,x,y).transpose(1, 2, 0)\n","    out = cv2.cvtColor(np.float32(out), cv2.COLOR_RGB2BGR)\n","\n","    return out\n","  "]},{"cell_type":"code","execution_count":20,"metadata":{"id":"D-2_NuLkg_-m","executionInfo":{"status":"ok","timestamp":1680954296184,"user_tz":-330,"elapsed":9,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["class VOCDataset(Dataset):\n","    \n","    def __init__(self, dataframe, image_dir, transforms=None):\n","        super().__init__()\n","        \n","        self.image_ids = dataframe['img_id'].unique()\n","        self.df = dataframe\n","        self.image_dir = image_dir\n","        self.transforms = transforms\n","    \n","    def __getitem__(self, index: int):\n","        image_id = self.image_ids[index]\n","        records = self.df[self.df['img_id'] == image_id]\n","        \n","        image = cv2.imread(f'{self.image_dir}/{image_id}.jpg', cv2.IMREAD_COLOR)\n","        image = func(image)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n","        image /= 255.0\n","        rows, cols = image.shape[:2]\n","        \n","        boxes = records[['xmin', 'ymin', 'xmax', 'ymax']].values\n","        \n","       \n","        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n","        area = torch.as_tensor(area, dtype=torch.float32)\n","        \n","        label = records['labels'].values\n","        labels = torch.as_tensor(label, dtype=torch.int64)\n","        \n","        # suppose all instances are not crowd\n","        iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n","        \n","        target = {}\n","        target['boxes'] = boxes\n","        target['labels'] = labels\n","        # target['masks'] = None\n","        target['image_id'] = torch.tensor([index])\n","        target['area'] = area\n","        target['iscrowd'] = iscrowd\n","        \n","        if self.transforms:\n","            sample = {\n","                'image': image,\n","                'bboxes': target['boxes'],\n","                'labels': labels\n","            }\n","            sample = self.transforms(**sample)\n","            image = sample['image']\n","            \n","            target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1,0)\n","            \n","            return image, target\n","        \n","    def __len__(self) -> int:\n","        return self.image_ids.shape[0]"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"h3-oAySag_-n","executionInfo":{"status":"ok","timestamp":1680954296185,"user_tz":-330,"elapsed":10,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["def get_transform_train():\n","    return A.Compose([\n","        A.HorizontalFlip(p=0.5),\n","        A.RandomBrightnessContrast(p=0.2),\n","        ToTensorV2(p=1.0)\n","    ], bbox_params={'format':'pascal_voc', 'label_fields': ['labels']})\n","\n","def get_transform_valid():\n","    return A.Compose([\n","        ToTensorV2(p=1.0)\n","    ], bbox_params={'format': 'pascal_voc', 'label_fields':['labels']})"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1680954296185,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"cfWNyTMWg_-n","outputId":"ba782597-61ea-41d5-ac63-18c8ff243797"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["def collate_fn(batch):\n","    return tuple(zip(*batch))\n","\n","train_dataset = VOCDataset(train_df, IMG_PATH , get_transform_train())\n","valid_dataset = VOCDataset(valid_df, IMG_PATH, get_transform_valid())\n","\n","\n","# split the dataset in train and test set\n","indices = torch.randperm(len(train_dataset)).tolist()\n","\n","\n","train_data_loader = DataLoader(\n","    train_dataset,\n","    batch_size=4,\n","    shuffle=True,\n","    num_workers=4,\n","    collate_fn=collate_fn\n",")\n","\n","valid_data_loader = DataLoader(\n","    valid_dataset,\n","    batch_size=4,\n","    shuffle=False,\n","    num_workers=4,\n","    collate_fn=collate_fn\n",")"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"VV2IexHNg_-o","executionInfo":{"status":"ok","timestamp":1680954296185,"user_tz":-330,"elapsed":8,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1O12LYATSdeOubGHAv3YHGQhriYvdx0JP","height":1000},"id":"DIdYOvrkg_-o","outputId":"8973187e-ce44-4237-eab3-36714459348e","executionInfo":{"status":"ok","timestamp":1680954327394,"user_tz":-330,"elapsed":31216,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["images, targets= next(iter(train_data_loader))\n","images = list(image.to(device) for image in images)\n","targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","plt.figure(figsize=(20,20))\n","for i, (image, target) in enumerate(zip(images, targets)):\n","    plt.subplot(2,2, i+1)\n","    boxes = targets[i]['boxes'].cpu().numpy().astype(np.int32)\n","    sample = images[i].permute(1,2,0).cpu().numpy()\n","    names = targets[i]['labels'].cpu().numpy().astype(np.int64)\n","    for i,box in enumerate(boxes):\n","        cv2.rectangle(sample,\n","                      (box[0], box[1]),\n","                      (box[2], box[3]),\n","                      (0, 0, 220), 2)\n","        cv2.putText(sample, classes[names[i]], (box[0],box[1]+15),cv2.FONT_HERSHEY_COMPLEX ,0.5,(0,220,0),1,cv2.LINE_AA)  \n","\n","    plt.axis('off')\n","    plt.imshow(sample)\n","    "]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":887,"status":"ok","timestamp":1680954328271,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"MZuDSLpIg_-p","outputId":"ddc3f289-531f-4b3e-a851-fe045ac65a5a"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n","100%|██████████| 160M/160M [00:00<00:00, 205MB/s]\n"]}],"source":["# load a model; pre-trained on COCO\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"ovW_8cxmg_-p","executionInfo":{"status":"ok","timestamp":1680954328271,"user_tz":-330,"elapsed":12,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["num_classes = 12\n","\n","# get number of input features for the classifier\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","\n","# replace the pre-trained head with a new one\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"CavTpFzNg_-q","executionInfo":{"status":"ok","timestamp":1680954328272,"user_tz":-330,"elapsed":13,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["model.to(device)\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005, weight_decay=0.0005)\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7093,"status":"ok","timestamp":1680954335353,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"4JyxrgvJg_-q","outputId":"9d3d5c26-4e6c-4cd6-cfe2-eb8714dc45c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n","  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-37nn7qka\n","  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-37nn7qka\n","  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.9/dist-packages (from pycocotools==2.0) (67.6.1)\n","Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.9/dist-packages (from pycocotools==2.0) (0.29.34)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from pycocotools==2.0) (3.7.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.11.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.0.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (23.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.4)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.22.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.0.7)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (5.12.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (8.4.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=2.1.0->pycocotools==2.0) (3.15.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0) (1.16.0)\n","Building wheels for collected packages: pycocotools\n","  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycocotools: filename=pycocotools-2.0-cp39-cp39-linux_x86_64.whl size=397998 sha256=cb9ff98f951879711804743b353873bee15dfbcb904b0310cf4549edcf09e260\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-nlohut2x/wheels/13/c1/d6/a321055f7089f1a6af654fbf794536b196999f082a9cb68a37\n","Successfully built pycocotools\n","Installing collected packages: pycocotools\n","  Attempting uninstall: pycocotools\n","    Found existing installation: pycocotools 2.0.6\n","    Uninstalling pycocotools-2.0.6:\n","      Successfully uninstalled pycocotools-2.0.6\n","Successfully installed pycocotools-2.0\n"]}],"source":["!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4969,"status":"ok","timestamp":1680954340314,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"kKqulq9Lg_-r","outputId":"5e7e3859-f4f1-4a22-80eb-ccd28b644221"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'vision' already exists and is not an empty directory.\n"]}],"source":["!git clone https://github.com/pytorch/vision.git\n","!cd vision;cp references/detection/utils.py ../;cp references/detection/transforms.py ../;cp references/detection/coco_eval.py ../;cp references/detection/engine.py ../;cp references/detection/coco_utils.py ../"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"VggsFCZ5g_-r","executionInfo":{"status":"ok","timestamp":1680954342897,"user_tz":-330,"elapsed":2586,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["from engine import train_one_epoch, evaluate\n","import utils"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":587361,"status":"ok","timestamp":1680954930247,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"K-Idxjreg_-r","outputId":"26eef47e-a003-4482-f40c-9d0050e93ad7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: [0]  [  0/216]  eta: 1:07:38  lr: 0.000028  loss: 3.2374 (3.2374)  loss_classifier: 2.6340 (2.6340)  loss_box_reg: 0.3444 (0.3444)  loss_objectness: 0.1659 (0.1659)  loss_rpn_box_reg: 0.0931 (0.0931)  time: 18.7915  data: 6.0684  max mem: 4239\n","Epoch: [0]  [ 10/216]  eta: 0:10:05  lr: 0.000261  loss: 3.1792 (3.2734)  loss_classifier: 2.5869 (2.5487)  loss_box_reg: 0.3298 (0.2942)  loss_objectness: 0.1659 (0.3168)  loss_rpn_box_reg: 0.0931 (0.1137)  time: 2.9371  data: 0.6775  max mem: 4242\n","Epoch: [0]  [ 20/216]  eta: 0:07:10  lr: 0.000493  loss: 2.7978 (2.9465)  loss_classifier: 2.3657 (2.2865)  loss_box_reg: 0.2772 (0.2848)  loss_objectness: 0.1422 (0.2559)  loss_rpn_box_reg: 0.0802 (0.1194)  time: 1.3689  data: 0.1448  max mem: 4456\n","Epoch: [0]  [ 30/216]  eta: 0:05:50  lr: 0.000725  loss: 2.1524 (2.5516)  loss_classifier: 1.5590 (1.9221)  loss_box_reg: 0.2437 (0.2753)  loss_objectness: 0.1336 (0.2155)  loss_rpn_box_reg: 0.1304 (0.1387)  time: 1.3087  data: 0.1392  max mem: 4456\n","Epoch: [0]  [ 40/216]  eta: 0:05:03  lr: 0.000958  loss: 1.3576 (2.2153)  loss_classifier: 0.7200 (1.6057)  loss_box_reg: 0.2244 (0.2636)  loss_objectness: 0.1328 (0.2077)  loss_rpn_box_reg: 0.1432 (0.1382)  time: 1.2254  data: 0.1146  max mem: 4456\n","Epoch: [0]  [ 50/216]  eta: 0:04:32  lr: 0.001190  loss: 1.1077 (1.9932)  loss_classifier: 0.5753 (1.3997)  loss_box_reg: 0.2261 (0.2711)  loss_objectness: 0.1348 (0.1920)  loss_rpn_box_reg: 0.0999 (0.1304)  time: 1.2588  data: 0.1034  max mem: 4456\n","Epoch: [0]  [ 60/216]  eta: 0:04:06  lr: 0.001422  loss: 1.0439 (1.8561)  loss_classifier: 0.5033 (1.2563)  loss_box_reg: 0.2773 (0.2799)  loss_objectness: 0.1308 (0.1859)  loss_rpn_box_reg: 0.1040 (0.1340)  time: 1.2952  data: 0.1134  max mem: 4456\n","Epoch: [0]  [ 70/216]  eta: 0:03:45  lr: 0.001655  loss: 0.9309 (1.7525)  loss_classifier: 0.4378 (1.1402)  loss_box_reg: 0.2692 (0.2797)  loss_objectness: 0.1293 (0.1961)  loss_rpn_box_reg: 0.1380 (0.1365)  time: 1.3101  data: 0.1281  max mem: 4456\n","Epoch: [0]  [ 80/216]  eta: 0:03:26  lr: 0.001887  loss: 0.9131 (1.6580)  loss_classifier: 0.4011 (1.0476)  loss_box_reg: 0.2471 (0.2779)  loss_objectness: 0.1370 (0.1956)  loss_rpn_box_reg: 0.1339 (0.1368)  time: 1.3062  data: 0.1228  max mem: 4456\n","Epoch: [0]  [ 90/216]  eta: 0:03:07  lr: 0.002119  loss: 0.9234 (1.5791)  loss_classifier: 0.3844 (0.9756)  loss_box_reg: 0.2641 (0.2800)  loss_objectness: 0.1302 (0.1867)  loss_rpn_box_reg: 0.1204 (0.1368)  time: 1.2883  data: 0.1124  max mem: 4456\n","Epoch: [0]  [100/216]  eta: 0:02:52  lr: 0.002351  loss: 0.8962 (1.5073)  loss_classifier: 0.3411 (0.9110)  loss_box_reg: 0.2360 (0.2759)  loss_objectness: 0.1035 (0.1823)  loss_rpn_box_reg: 0.1058 (0.1381)  time: 1.3588  data: 0.1189  max mem: 4456\n","Epoch: [0]  [110/216]  eta: 0:02:35  lr: 0.002584  loss: 0.8375 (1.4556)  loss_classifier: 0.3113 (0.8600)  loss_box_reg: 0.2492 (0.2790)  loss_objectness: 0.1129 (0.1799)  loss_rpn_box_reg: 0.1225 (0.1368)  time: 1.3461  data: 0.1224  max mem: 4456\n","Epoch: [0]  [120/216]  eta: 0:02:19  lr: 0.002816  loss: 0.8149 (1.4041)  loss_classifier: 0.3078 (0.8149)  loss_box_reg: 0.2728 (0.2783)  loss_objectness: 0.1156 (0.1763)  loss_rpn_box_reg: 0.1221 (0.1347)  time: 1.2702  data: 0.1119  max mem: 4456\n","Epoch: [0]  [130/216]  eta: 0:02:03  lr: 0.003048  loss: 0.7224 (1.3484)  loss_classifier: 0.2692 (0.7720)  loss_box_reg: 0.2091 (0.2735)  loss_objectness: 0.0954 (0.1700)  loss_rpn_box_reg: 0.1219 (0.1329)  time: 1.2836  data: 0.1010  max mem: 4456\n","Epoch: [0]  [140/216]  eta: 0:01:48  lr: 0.003281  loss: 0.7224 (1.3111)  loss_classifier: 0.2666 (0.7359)  loss_box_reg: 0.2486 (0.2723)  loss_objectness: 0.1049 (0.1690)  loss_rpn_box_reg: 0.1238 (0.1338)  time: 1.3131  data: 0.1134  max mem: 4456\n","Epoch: [0]  [150/216]  eta: 0:01:33  lr: 0.003513  loss: 0.7294 (1.2731)  loss_classifier: 0.2465 (0.7018)  loss_box_reg: 0.2362 (0.2669)  loss_objectness: 0.1488 (0.1710)  loss_rpn_box_reg: 0.1171 (0.1334)  time: 1.3096  data: 0.1269  max mem: 4456\n","Epoch: [0]  [160/216]  eta: 0:01:19  lr: 0.003745  loss: 0.7468 (1.2487)  loss_classifier: 0.2671 (0.6775)  loss_box_reg: 0.2519 (0.2698)  loss_objectness: 0.1367 (0.1676)  loss_rpn_box_reg: 0.1038 (0.1338)  time: 1.3143  data: 0.1232  max mem: 4456\n","Epoch: [0]  [170/216]  eta: 0:01:04  lr: 0.003978  loss: 0.7468 (1.2145)  loss_classifier: 0.2671 (0.6518)  loss_box_reg: 0.2519 (0.2663)  loss_objectness: 0.1062 (0.1648)  loss_rpn_box_reg: 0.1002 (0.1316)  time: 1.3219  data: 0.1141  max mem: 4456\n","Epoch: [0]  [180/216]  eta: 0:00:50  lr: 0.004210  loss: 0.6844 (1.1898)  loss_classifier: 0.2357 (0.6302)  loss_box_reg: 0.2204 (0.2639)  loss_objectness: 0.1176 (0.1634)  loss_rpn_box_reg: 0.1006 (0.1323)  time: 1.2888  data: 0.1037  max mem: 4456\n","Epoch: [0]  [190/216]  eta: 0:00:36  lr: 0.004442  loss: 0.8381 (1.1685)  loss_classifier: 0.2624 (0.6109)  loss_box_reg: 0.2332 (0.2635)  loss_objectness: 0.1255 (0.1624)  loss_rpn_box_reg: 0.1240 (0.1317)  time: 1.3023  data: 0.1178  max mem: 4456\n","Epoch: [0]  [200/216]  eta: 0:00:22  lr: 0.004675  loss: 0.7294 (1.1456)  loss_classifier: 0.2624 (0.5935)  loss_box_reg: 0.2339 (0.2633)  loss_objectness: 0.1081 (0.1585)  loss_rpn_box_reg: 0.1007 (0.1303)  time: 1.3121  data: 0.1250  max mem: 4456\n","Epoch: [0]  [210/216]  eta: 0:00:08  lr: 0.004907  loss: 0.7320 (1.1278)  loss_classifier: 0.2598 (0.5786)  loss_box_reg: 0.2373 (0.2630)  loss_objectness: 0.0958 (0.1561)  loss_rpn_box_reg: 0.1041 (0.1301)  time: 1.2977  data: 0.1143  max mem: 4456\n","Epoch: [0]  [215/216]  eta: 0:00:01  lr: 0.005000  loss: 0.7599 (1.1217)  loss_classifier: 0.2879 (0.5729)  loss_box_reg: 0.2658 (0.2640)  loss_objectness: 0.0967 (0.1548)  loss_rpn_box_reg: 0.1218 (0.1299)  time: 1.1815  data: 0.0822  max mem: 4456\n","Epoch: [0] Total time: 0:04:57 (1.3784 s / it)\n","creating index...\n","index created!\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Test:  [0/1]  eta: 0:00:01  model_time: 0.4834 (0.4834)  evaluator_time: 0.0426 (0.0426)  time: 1.7556  data: 1.1914  max mem: 4456\n","Test: Total time: 0:00:01 (1.8880 s / it)\n","Averaged stats: model_time: 0.4834 (0.4834)  evaluator_time: 0.0426 (0.0426)\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n","IoU metric: bbox\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.050\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.092\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.066\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.005\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.021\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.117\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.025\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.136\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.146\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.025\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.136\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.210\n","Epoch: [1]  [  0/216]  eta: 0:20:17  lr: 0.005000  loss: 0.9388 (0.9388)  loss_classifier: 0.3041 (0.3041)  loss_box_reg: 0.2639 (0.2639)  loss_objectness: 0.1057 (0.1057)  loss_rpn_box_reg: 0.2651 (0.2651)  time: 5.6375  data: 4.2574  max mem: 4456\n","Epoch: [1]  [ 10/216]  eta: 0:06:16  lr: 0.005000  loss: 0.7380 (0.7846)  loss_classifier: 0.2727 (0.2920)  loss_box_reg: 0.2726 (0.2956)  loss_objectness: 0.0757 (0.0822)  loss_rpn_box_reg: 0.0969 (0.1148)  time: 1.8289  data: 0.5228  max mem: 4456\n","Epoch: [1]  [ 20/216]  eta: 0:05:12  lr: 0.005000  loss: 0.7942 (0.8598)  loss_classifier: 0.3148 (0.3198)  loss_box_reg: 0.3291 (0.3355)  loss_objectness: 0.0771 (0.0955)  loss_rpn_box_reg: 0.0844 (0.1090)  time: 1.3934  data: 0.1325  max mem: 4456\n","Epoch: [1]  [ 30/216]  eta: 0:04:37  lr: 0.005000  loss: 0.8097 (0.8226)  loss_classifier: 0.2758 (0.3019)  loss_box_reg: 0.2950 (0.3040)  loss_objectness: 0.0909 (0.1008)  loss_rpn_box_reg: 0.0834 (0.1160)  time: 1.3073  data: 0.1138  max mem: 4456\n","Epoch: [1]  [ 40/216]  eta: 0:04:14  lr: 0.005000  loss: 0.7937 (0.8222)  loss_classifier: 0.2665 (0.3018)  loss_box_reg: 0.2352 (0.2970)  loss_objectness: 0.0910 (0.1034)  loss_rpn_box_reg: 0.1345 (0.1200)  time: 1.2837  data: 0.1059  max mem: 4456\n","Epoch: [1]  [ 50/216]  eta: 0:03:55  lr: 0.005000  loss: 0.6791 (0.7821)  loss_classifier: 0.2632 (0.2871)  loss_box_reg: 0.2298 (0.2778)  loss_objectness: 0.0936 (0.1016)  loss_rpn_box_reg: 0.1264 (0.1157)  time: 1.3029  data: 0.1065  max mem: 4456\n","Epoch: [1]  [ 60/216]  eta: 0:03:37  lr: 0.005000  loss: 0.6791 (0.7852)  loss_classifier: 0.2379 (0.2865)  loss_box_reg: 0.2229 (0.2760)  loss_objectness: 0.0899 (0.1000)  loss_rpn_box_reg: 0.1006 (0.1227)  time: 1.3001  data: 0.1109  max mem: 4456\n","Epoch: [1]  [ 70/216]  eta: 0:03:21  lr: 0.005000  loss: 0.6875 (0.7672)  loss_classifier: 0.2469 (0.2804)  loss_box_reg: 0.2354 (0.2652)  loss_objectness: 0.0891 (0.1003)  loss_rpn_box_reg: 0.1188 (0.1212)  time: 1.2783  data: 0.1036  max mem: 4456\n","Epoch: [1]  [ 80/216]  eta: 0:03:04  lr: 0.005000  loss: 0.6453 (0.7591)  loss_classifier: 0.2511 (0.2768)  loss_box_reg: 0.2138 (0.2585)  loss_objectness: 0.0887 (0.1027)  loss_rpn_box_reg: 0.1188 (0.1210)  time: 1.2466  data: 0.0964  max mem: 4456\n","Epoch: [1]  [ 90/216]  eta: 0:02:50  lr: 0.005000  loss: 0.6460 (0.7517)  loss_classifier: 0.2584 (0.2739)  loss_box_reg: 0.2263 (0.2546)  loss_objectness: 0.0828 (0.1023)  loss_rpn_box_reg: 0.1239 (0.1210)  time: 1.2659  data: 0.1013  max mem: 4456\n","Epoch: [1]  [100/216]  eta: 0:02:36  lr: 0.005000  loss: 0.6460 (0.7400)  loss_classifier: 0.2439 (0.2717)  loss_box_reg: 0.2345 (0.2503)  loss_objectness: 0.0704 (0.0991)  loss_rpn_box_reg: 0.0899 (0.1189)  time: 1.3064  data: 0.1150  max mem: 4456\n","Epoch: [1]  [110/216]  eta: 0:02:22  lr: 0.005000  loss: 0.6230 (0.7379)  loss_classifier: 0.2434 (0.2710)  loss_box_reg: 0.2023 (0.2503)  loss_objectness: 0.0672 (0.0974)  loss_rpn_box_reg: 0.1042 (0.1192)  time: 1.2771  data: 0.1067  max mem: 4456\n","Epoch: [1]  [120/216]  eta: 0:02:08  lr: 0.005000  loss: 0.7613 (0.7444)  loss_classifier: 0.2978 (0.2744)  loss_box_reg: 0.2820 (0.2548)  loss_objectness: 0.0749 (0.0957)  loss_rpn_box_reg: 0.1202 (0.1196)  time: 1.2866  data: 0.0991  max mem: 4456\n","Epoch: [1]  [130/216]  eta: 0:01:54  lr: 0.005000  loss: 0.6922 (0.7385)  loss_classifier: 0.2672 (0.2729)  loss_box_reg: 0.2229 (0.2520)  loss_objectness: 0.0677 (0.0936)  loss_rpn_box_reg: 0.1202 (0.1200)  time: 1.3017  data: 0.1038  max mem: 4456\n","Epoch: [1]  [140/216]  eta: 0:01:40  lr: 0.005000  loss: 0.5812 (0.7275)  loss_classifier: 0.2295 (0.2694)  loss_box_reg: 0.1766 (0.2475)  loss_objectness: 0.0666 (0.0937)  loss_rpn_box_reg: 0.0994 (0.1169)  time: 1.2628  data: 0.0974  max mem: 4456\n","Epoch: [1]  [150/216]  eta: 0:01:27  lr: 0.005000  loss: 0.5812 (0.7244)  loss_classifier: 0.2271 (0.2693)  loss_box_reg: 0.1870 (0.2452)  loss_objectness: 0.0744 (0.0931)  loss_rpn_box_reg: 0.0846 (0.1169)  time: 1.2505  data: 0.0960  max mem: 4456\n","Epoch: [1]  [160/216]  eta: 0:01:13  lr: 0.005000  loss: 0.6380 (0.7212)  loss_classifier: 0.2323 (0.2681)  loss_box_reg: 0.2020 (0.2432)  loss_objectness: 0.0776 (0.0929)  loss_rpn_box_reg: 0.1012 (0.1170)  time: 1.2710  data: 0.1064  max mem: 4456\n","Epoch: [1]  [170/216]  eta: 0:01:00  lr: 0.005000  loss: 0.6397 (0.7223)  loss_classifier: 0.2323 (0.2685)  loss_box_reg: 0.1972 (0.2432)  loss_objectness: 0.0684 (0.0934)  loss_rpn_box_reg: 0.1309 (0.1173)  time: 1.2829  data: 0.1144  max mem: 4456\n","Epoch: [1]  [180/216]  eta: 0:00:47  lr: 0.005000  loss: 0.6262 (0.7180)  loss_classifier: 0.2166 (0.2658)  loss_box_reg: 0.1644 (0.2400)  loss_objectness: 0.0684 (0.0939)  loss_rpn_box_reg: 0.1309 (0.1183)  time: 1.2807  data: 0.1139  max mem: 4456\n","Epoch: [1]  [190/216]  eta: 0:00:34  lr: 0.005000  loss: 0.5585 (0.7105)  loss_classifier: 0.2013 (0.2630)  loss_box_reg: 0.1582 (0.2370)  loss_objectness: 0.0810 (0.0930)  loss_rpn_box_reg: 0.1139 (0.1175)  time: 1.2937  data: 0.1135  max mem: 4456\n","Epoch: [1]  [200/216]  eta: 0:00:21  lr: 0.005000  loss: 0.5585 (0.7080)  loss_classifier: 0.2094 (0.2626)  loss_box_reg: 0.1721 (0.2365)  loss_objectness: 0.0770 (0.0926)  loss_rpn_box_reg: 0.0909 (0.1162)  time: 1.3028  data: 0.1139  max mem: 4456\n","Epoch: [1]  [210/216]  eta: 0:00:07  lr: 0.005000  loss: 0.5717 (0.7026)  loss_classifier: 0.2296 (0.2617)  loss_box_reg: 0.1768 (0.2343)  loss_objectness: 0.0688 (0.0914)  loss_rpn_box_reg: 0.0789 (0.1151)  time: 1.2337  data: 0.0950  max mem: 4456\n","Epoch: [1]  [215/216]  eta: 0:00:01  lr: 0.005000  loss: 0.6754 (0.7059)  loss_classifier: 0.2644 (0.2631)  loss_box_reg: 0.2222 (0.2359)  loss_objectness: 0.0727 (0.0915)  loss_rpn_box_reg: 0.0950 (0.1154)  time: 1.1597  data: 0.0811  max mem: 4456\n","Epoch: [1] Total time: 0:04:40 (1.3001 s / it)\n","creating index...\n","index created!\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Test:  [0/1]  eta: 0:00:01  model_time: 0.4802 (0.4802)  evaluator_time: 0.0392 (0.0392)  time: 1.7674  data: 1.2092  max mem: 4456\n","Test: Total time: 0:00:01 (1.9081 s / it)\n","Averaged stats: model_time: 0.4802 (0.4802)  evaluator_time: 0.0392 (0.0392)\n","Accumulating evaluation results...\n","DONE (t=0.02s).\n","IoU metric: bbox\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.158\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.311\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.144\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.101\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.178\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.265\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.101\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.247\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.276\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.100\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.263\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.347\n","CPU times: user 4min 18s, sys: 21.3 s, total: 4min 39s\n","Wall time: 9min 46s\n"]}],"source":["%%time\n","# let's train it for 1 epoch\n","num_epochs = 2\n","\n","for epoch in range(num_epochs):\n","    # train for one epoch, printing every 10 iterations\n","    train_one_epoch(model, optimizer, train_data_loader, device, epoch, print_freq=10)\n","    # update the learning rate\n","    lr_scheduler.step()\n","    # evaluate on the test dataset\n","    evaluate(model, valid_data_loader, device=device)"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"M8oQFNLMg_-s","executionInfo":{"status":"ok","timestamp":1680954930248,"user_tz":-330,"elapsed":16,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["torch.save(model.state_dict(), 'faster_rcnn_state3.pth')"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":877,"status":"ok","timestamp":1680954931120,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"b-G2lTWRg_-s","outputId":"778e1413-1959-4714-f9e7-f17b815d031f"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained_backbone' is deprecated since 0.13 and may be removed in the future, please use 'weights_backbone' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights_backbone' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights_backbone=None`.\n","  warnings.warn(msg)\n"]}],"source":["# load  a model; pre-trained on COCO\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, pretrained_backbone=False)\n","\n","WEIGHTS_FILE = \"./faster_rcnn_state3.pth\"\n","\n","num_classes = 12\n","\n","# get number of input features for the classifier\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","\n","# replace the pre-trained head with a new one\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","# Load the traines weights\n","model.load_state_dict(torch.load(WEIGHTS_FILE))\n","\n","model = model.to(device)\n"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"ISQInM55g_-t","executionInfo":{"status":"ok","timestamp":1680954931120,"user_tz":-330,"elapsed":6,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["def obj_detector(img):\n","    img = cv2.imread(img, cv2.IMREAD_COLOR)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n","\n","\n","    img /= 255.0\n","    img = torch.from_numpy(img)\n","    img = img.unsqueeze(0)\n","    img = img.permute(0,3,1,2)\n","    \n","    model.eval()\n","\n","    detection_threshold = 0.70\n","    \n","    img = list(im.to(device) for im in img)\n","    output = model(img)\n","\n","    for i , im in enumerate(img):\n","        boxes = output[i]['boxes'].data.cpu().numpy()\n","        scores = output[i]['scores'].data.cpu().numpy()\n","        labels = output[i]['labels'].data.cpu().numpy()\n","\n","        labels = labels[scores >= detection_threshold]\n","        boxes = boxes[scores >= detection_threshold].astype(np.int32)\n","        scores = scores[scores >= detection_threshold]\n","\n","        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n","        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n","    \n","    sample = img[0].permute(1,2,0).cpu().numpy()\n","    sample = np.array(sample)\n","    boxes = output[0]['boxes'].data.cpu().numpy()\n","    name = output[0]['labels'].data.cpu().numpy()\n","    scores = output[0]['scores'].data.cpu().numpy()\n","    boxes = boxes[scores >= detection_threshold].astype(np.int32)\n","    names = name.tolist()\n","    \n","    return names, boxes, sample"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13131,"status":"ok","timestamp":1680956335484,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"rlpYQbaDg_-t","outputId":"f5695147-2a52-4471-8d52-6ce1e9fc8a61"},"outputs":[{"output_type":"stream","name":"stdout","text":["0 ./test2/0000007_05999_d_0000038.jpg\n","1 ./test2/0000002_00005_d_0000014.jpg\n","2 ./test2/0000072_00000_d_0000001.jpg\n","3 ./test2/0000107_02196_d_0000055.jpg\n","4 ./test2/0000072_07660_d_0000012.jpg\n","5 ./test2/0000008_00889_d_0000039.jpg\n","6 ./test2/0000008_03499_d_0000043.jpg\n","7 ./test2/0000008_03999_d_0000044.jpg\n","8 ./test2/0000008_04499_d_0000045.jpg\n","9 ./test2/0000008_02999_d_0000042.jpg\n","10 ./test2/0000008_02499_d_0000041.jpg\n","11 ./test2/0000008_01999_d_0000040.jpg\n","12 ./test2/0000036_00500_d_0000046.jpg\n","13 ./test2/0000031_02000_d_0000041.jpg\n","14 ./test2/0000031_03527_d_0000043.jpg\n","15 ./test2/0000031_00000_d_0000037.jpg\n","16 ./test2/9999999_00301_d_0000133.jpg\n","17 ./test2/9999999_00299_d_0000132.jpg\n","18 ./test2/0000040_04284_d_0000071.jpg\n","19 ./test2/0000040_02454_d_0000068.jpg\n","20 ./test2/0000040_03288_d_0000069.jpg\n","21 ./test2/0000040_03752_d_0000070.jpg\n","22 ./test2/0000040_01500_d_0000067.jpg\n","23 ./test2/0000040_01000_d_0000066.jpg\n","24 ./test2/0000039_05300_d_0000061.jpg\n","25 ./test2/0000039_00000_d_0000055.jpg\n","26 ./test2/0000037_01494_d_0000052.jpg\n","27 ./test2/0000039_05625_d_0000062.jpg\n","28 ./test2/0000036_03591_d_0000048.jpg\n","29 ./test2/9999999_00330_d_0000144.jpg\n","30 ./test2/9999999_00332_d_0000145.jpg\n","31 ./test2/9999999_00328_d_0000143.jpg\n","32 ./test2/9999999_00326_d_0000142.jpg\n","33 ./test2/9999999_00322_d_0000141.jpg\n","34 ./test2/9999999_00320_d_0000140.jpg\n","35 ./test2/9999999_00318_d_0000139.jpg\n","36 ./test2/9999999_00313_d_0000138.jpg\n","37 ./test2/9999999_00309_d_0000137.jpg\n","38 ./test2/9999999_00307_d_0000136.jpg\n","39 ./test2/9999999_00303_d_0000134.jpg\n","40 ./test2/9999999_00305_d_0000135.jpg\n","41 ./test2/9999999_00354_d_0000154.jpg\n","42 ./test2/9999999_00356_d_0000155.jpg\n","43 ./test2/9999999_00348_d_0000153.jpg\n","44 ./test2/9999999_00346_d_0000152.jpg\n","45 ./test2/9999999_00342_d_0000150.jpg\n","46 ./test2/9999999_00344_d_0000151.jpg\n","47 ./test2/9999999_00340_d_0000149.jpg\n","48 ./test2/9999999_00338_d_0000148.jpg\n","49 ./test2/9999999_00336_d_0000147.jpg\n"]}],"source":["pred_path = \"./test2\"\n","pred_files = [os.path.join(pred_path,f) for f in os.listdir(pred_path)]\n","\n","for i, images in enumerate(pred_files):\n","    print(i,images)\n","    names,boxes,sample = obj_detector(images)\n","\n","    img = cv2.imread(images)\n","    \n","    for i,box in enumerate(boxes):\n","        cv2.rectangle(img,\n","                      (box[0], box[1]),\n","                      (box[2], box[3]),\n","                      (0, 220, 0), 2)  \n","\n","    cv2.imwrite(f'./test3/{images[7:]}',img)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1V0y9Jo0CKCAU2vg6hy8V9vHxUauNk0lz","timestamp":1679820769372}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}