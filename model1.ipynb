{"cells":[{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7998,"status":"ok","timestamp":1680951984713,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"AYTJICU8mTMX","outputId":"badaed6b-303e-4f78-8293-7296d21fe2fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1680951984714,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"nKm2GBdCmU2s","outputId":"11dcc788-18cb-4ffc-e761-c324930b5e38"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/data_visualization/datavis_data\n"]}],"source":["cd /content/gdrive/MyDrive/data_visualization/datavis_data/"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1680951984714,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"lte9XrLRhFVx"},"outputs":[],"source":["import os\n","import collections\n","import pandas as pd\n","import numpy as np\n","import functools\n","import matplotlib.pyplot as plt\n","import cv2\n","\n","from sklearn import preprocessing \n","\n","\n","import xml.etree.ElementTree as ET\n","\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2\n","\n","import torch\n","import torchvision\n","\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection import FasterRCNN\n","from torchvision.models.detection.rpn import AnchorGenerator\n","\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.data import SequentialSampler"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23951,"status":"ok","timestamp":1680949988525,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"8oUILFDVg_-P","outputId":"ef15b108-c916-47c0-cb34-b11be8b6d176"},"outputs":[{"data":{"text/plain":["1000"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["XML_PATH = \"annotation\"\n","IMG_PATH = \"train\"\n","XML_FILES = [os.path.join(XML_PATH, f) for f in os.listdir(XML_PATH)]\n","XML_FILES = XML_FILES[:1000] #first 1000\n","\n","len(XML_FILES)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O_U86BV5g_-Z"},"outputs":[],"source":["class XmlParser(object):\n","\n","    def __init__(self,xml_file):\n","\n","        self.xml_file = self.filter(xml_file)\n","        \n","        # path to the image file = name of annotation file\n","        self.img_name = xml_file.split('/')[1].split('.')[0]+\".jpg\";\n","        self.img_path = os.path.join(IMG_PATH, self.img_name)\n","\n","        # image id \n","        self.image_id = self.img_name.split('.')[0];\n","\n","        # names of the classes contained in the xml file\n","        self.names = self._get_names()\n","        # coordinates of the bounding boxes\n","        self.boxes = self._get_bndbox()\n","\n","    def filter(self,xml_file):\n","\n","        filtered_data = []\n","\n","        f = open(xml_file, 'r')\n","\n","        for line in f:\n","            data = line.split(',')\n","            if data[5]!='0' and (data[5]=='3' or data[5]=='4'):\n","                data = [int(x.strip()) for x in data]\n","                filtered_data.append(data)\n","\n","                #augmentation for people\n","                if data[5]=='1' or data[5]=='2':\n","                  filtered_data.append(data)\n","\n","        return filtered_data\n","\n","    def _get_names(self):\n","\n","        label_dict = {\n","                      0 : \"Ignore\",\n","                      1 : \"Pedestrian\",\n","                      2 : \"People\",\n","                      3 : \"Bicycle\",\n","                      4 : \"Car\",\n","                      5 : \"Van\",\n","                      6 : \"Truck\",\n","                      7 : \"Tricycle\",\n","                      8 : \"Awning-tricycle\",\n","                      9 : \"Bus\",\n","                      10 : \"Motor\",\n","                      11 : \"Others\"\n","                    }\n","\n","        names = []\n","\n","        for data in self.xml_file:\n","              class_id = data[5]\n","              names.append(label_dict[class_id])\n","\n","        return np.array(names)\n","\n","    def _get_bndbox(self):\n","\n","        boxes = []\n","\n","        for data in self.xml_file:\n","            \n","            coordinates = []\n","            coordinates.append(np.int32(data[0])) #xmin\n","            coordinates.append(np.int32(np.float32(data[1]))) #ymin\n","            coordinates.append(np.int32(data[2]+data[0])) #xmax\n","            coordinates.append(np.int32(data[3]+data[1])) #ymax\n","            boxes.append(coordinates)\n","\n","        return np.array(boxes)\n","\n","# xml = XmlParser('Annotations/0000007_05999_d_0000038.txt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":130370,"status":"ok","timestamp":1680950124830,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"_NvoeGhmi6Rh","outputId":"239581fb-9e64-457e-e611-75668baa9cbc"},"outputs":[{"data":{"text/plain":["29433"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["def xml_files_to_df(xml_files):\n","    \n","    \"\"\"\"Return pandas dataframe from list of XML files.\"\"\"\n","    \n","    names = []\n","    boxes = []\n","    image_id = []\n","    xml_path = []\n","    img_path = []\n","    for file in xml_files:\n","        xml = XmlParser(file)\n","        names.extend(xml.names)\n","        boxes.extend(xml.boxes)\n","        image_id.extend([xml.image_id] * len(xml.names))\n","        xml_path.extend([xml.xml_file] * len(xml.names))\n","        img_path.extend([xml.img_path] * len(xml.names))\n","    a = {\"img_id\": image_id,\n","         \"names\": names,\n","         \"boxes\": boxes,\n","         \"xml_path\":xml_path,\n","         \"img_path\":img_path}\n","    \n","    df = pd.DataFrame.from_dict(a, orient='index')\n","    df = df.transpose()\n","    \n","    return df\n","\n","df = xml_files_to_df(XML_FILES)\n","df.head()\n","df.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1680950124831,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"UL91oDD4g_-c","outputId":"040c95b6-8b9e-4b02-de82-7bacbc4eca7f"},"outputs":[{"data":{"text/plain":["Car        26536\n","Bicycle     2897\n","Name: names, dtype: int64"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# check values for per class\n","df['names'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":604,"status":"ok","timestamp":1680950172847,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"Ui-v8WIHg_-d","outputId":"73d7d33d-6166-45c6-9128-fd15dcc6059b"},"outputs":[{"data":{"text/plain":["0         [842, 737, 912, 870]\n","1         [847, 604, 902, 685]\n","2        [566, 961, 651, 1050]\n","3        [668, 858, 743, 1003]\n","4         [625, 827, 688, 940]\n","                 ...          \n","29428     [1651, 13, 1679, 24]\n","29429     [1652, 18, 1682, 31]\n","29430     [1661, 33, 1692, 46]\n","29431     [1667, 30, 1694, 43]\n","29432     [1669, 29, 1696, 40]\n","Name: boxes, Length: 29433, dtype: object"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df['boxes']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1680950176477,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"D_sTTUxBg_-e","outputId":"5b5b146e-ccc1-4728-af2d-d1ef734265eb"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py:3473: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  if (await self.run_code(code, result,  async_=asy)):\n"]}],"source":["# classes need to be in int form so we use LabelEncoder for this task\n","enc = preprocessing.LabelEncoder()\n","df['labels'] = enc.fit_transform(df['names'])\n","df['labels'] = np.stack(df['labels'][i]+1 for i in range(len(df['labels']))) "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1680950180434,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"byc5kANsg_-f","outputId":"d47eb607-c361-415e-c447-b0f652385070"},"outputs":[{"data":{"text/plain":["names    labels\n","Car      2         26536\n","Bicycle  1          2897\n","dtype: int64"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["classes = df[['names','labels']].value_counts()\n","classes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1680950180435,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"9a-7b1bKsj89","outputId":"06ea98f8-6324-4f07-c71f-ad3f018c72e1"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-261e9514-df83-42ff-9fb6-31a0465ef8d0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>img_id</th>\n","      <th>names</th>\n","      <th>boxes</th>\n","      <th>xml_path</th>\n","      <th>img_path</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>Car</td>\n","      <td>[842, 737, 912, 870]</td>\n","      <td>[[842, 737, 70, 133, 1, 4, 0, 0], [847, 604, 5...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>Car</td>\n","      <td>[847, 604, 902, 685]</td>\n","      <td>[[842, 737, 70, 133, 1, 4, 0, 0], [847, 604, 5...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>Car</td>\n","      <td>[566, 961, 651, 1050]</td>\n","      <td>[[842, 737, 70, 133, 1, 4, 0, 0], [847, 604, 5...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>Car</td>\n","      <td>[668, 858, 743, 1003]</td>\n","      <td>[[842, 737, 70, 133, 1, 4, 0, 0], [847, 604, 5...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>Car</td>\n","      <td>[625, 827, 688, 940]</td>\n","      <td>[[842, 737, 70, 133, 1, 4, 0, 0], [847, 604, 5...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-261e9514-df83-42ff-9fb6-31a0465ef8d0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-261e9514-df83-42ff-9fb6-31a0465ef8d0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-261e9514-df83-42ff-9fb6-31a0465ef8d0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                    img_id names                  boxes  \\\n","0  9999994_00000_d_0000055   Car   [842, 737, 912, 870]   \n","1  9999994_00000_d_0000055   Car   [847, 604, 902, 685]   \n","2  9999994_00000_d_0000055   Car  [566, 961, 651, 1050]   \n","3  9999994_00000_d_0000055   Car  [668, 858, 743, 1003]   \n","4  9999994_00000_d_0000055   Car   [625, 827, 688, 940]   \n","\n","                                            xml_path  \\\n","0  [[842, 737, 70, 133, 1, 4, 0, 0], [847, 604, 5...   \n","1  [[842, 737, 70, 133, 1, 4, 0, 0], [847, 604, 5...   \n","2  [[842, 737, 70, 133, 1, 4, 0, 0], [847, 604, 5...   \n","3  [[842, 737, 70, 133, 1, 4, 0, 0], [847, 604, 5...   \n","4  [[842, 737, 70, 133, 1, 4, 0, 0], [847, 604, 5...   \n","\n","                            img_path  labels  \n","0  train/9999994_00000_d_0000055.jpg       2  \n","1  train/9999994_00000_d_0000055.jpg       2  \n","2  train/9999994_00000_d_0000055.jpg       2  \n","3  train/9999994_00000_d_0000055.jpg       2  \n","4  train/9999994_00000_d_0000055.jpg       2  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZPxyczp5g_-g"},"outputs":[],"source":["classes = {\n","                      1 : \"Bicycle\",\n","                      2 : \"Car\",\n","                    }"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":897,"status":"ok","timestamp":1680950220059,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"NFVN1DODg_-h","outputId":"82f85fe9-1fe9-43d6-be4c-39f26e4d55de"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py:3473: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  if (await self.run_code(code, result,  async_=asy)):\n"]}],"source":["#bounding box coordinates point need to be in separate columns\n","\n","df['xmin'] = -1\n","df['ymin'] = -1\n","df['xmax'] = -1\n","df['ymax'] = -1\n","\n","df[['xmin','ymin','xmax','ymax']]=np.stack(df['boxes'][i] for i in range(len(df['boxes'])))\n","\n","df.drop(columns=['boxes'], inplace=True)\n","df['xmin'] = df['xmin'].astype(float)\n","df['ymin'] = df['ymin'].astype(float)\n","df['xmax'] = df['xmax'].astype(float)\n","df['ymax'] = df['ymax'].astype(float)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":1102,"status":"ok","timestamp":1680950222009,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"OpjbwFXAg_-i","outputId":"9d8610b4-bad5-440d-d54e-abc39709de5f"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-f341378e-730d-406a-88b7-f81c66168acf\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>img_id</th>\n","      <th>xml_path</th>\n","      <th>img_path</th>\n","      <th>labels</th>\n","      <th>xmin</th>\n","      <th>ymin</th>\n","      <th>xmax</th>\n","      <th>ymax</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>[[842, 737, 70, 133, 1, 4, 0, 0], [847, 604, 5...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","      <td>842.0</td>\n","      <td>737.0</td>\n","      <td>912.0</td>\n","      <td>870.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>[[842, 737, 70, 133, 1, 4, 0, 0], [847, 604, 5...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","      <td>847.0</td>\n","      <td>604.0</td>\n","      <td>902.0</td>\n","      <td>685.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>[[842, 737, 70, 133, 1, 4, 0, 0], [847, 604, 5...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","      <td>566.0</td>\n","      <td>961.0</td>\n","      <td>651.0</td>\n","      <td>1050.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>[[842, 737, 70, 133, 1, 4, 0, 0], [847, 604, 5...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","      <td>668.0</td>\n","      <td>858.0</td>\n","      <td>743.0</td>\n","      <td>1003.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>[[842, 737, 70, 133, 1, 4, 0, 0], [847, 604, 5...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","      <td>625.0</td>\n","      <td>827.0</td>\n","      <td>688.0</td>\n","      <td>940.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f341378e-730d-406a-88b7-f81c66168acf')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f341378e-730d-406a-88b7-f81c66168acf button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f341378e-730d-406a-88b7-f81c66168acf');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                    img_id                                           xml_path  \\\n","0  9999994_00000_d_0000055  [[842, 737, 70, 133, 1, 4, 0, 0], [847, 604, 5...   \n","1  9999994_00000_d_0000055  [[842, 737, 70, 133, 1, 4, 0, 0], [847, 604, 5...   \n","2  9999994_00000_d_0000055  [[842, 737, 70, 133, 1, 4, 0, 0], [847, 604, 5...   \n","3  9999994_00000_d_0000055  [[842, 737, 70, 133, 1, 4, 0, 0], [847, 604, 5...   \n","4  9999994_00000_d_0000055  [[842, 737, 70, 133, 1, 4, 0, 0], [847, 604, 5...   \n","\n","                            img_path  labels   xmin   ymin   xmax    ymax  \n","0  train/9999994_00000_d_0000055.jpg       2  842.0  737.0  912.0   870.0  \n","1  train/9999994_00000_d_0000055.jpg       2  847.0  604.0  902.0   685.0  \n","2  train/9999994_00000_d_0000055.jpg       2  566.0  961.0  651.0  1050.0  \n","3  train/9999994_00000_d_0000055.jpg       2  668.0  858.0  743.0  1003.0  \n","4  train/9999994_00000_d_0000055.jpg       2  625.0  827.0  688.0   940.0  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# drop names column since we dont need it anymore\n","df.drop(columns=['names'], inplace=True)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1095,"status":"ok","timestamp":1680950232862,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"m7RqwLzZg_-j","outputId":"604c45bd-3cf5-4218-a2c0-7bc1fa05f8ae"},"outputs":[{"data":{"text/plain":["983"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["len(df['img_id'].unique())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1680950236125,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"JYr0ORPlg_-j","outputId":"94c3d2d9-20f9-482d-b2ae-184e4522e09d"},"outputs":[{"data":{"text/plain":["979"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["image_ids = df['img_id'].unique()\n","valid_ids = image_ids[-4:]\n","train_ids = image_ids[:-4]\n","len(train_ids)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1680950237131,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"W96Vu4Hpg_-k","outputId":"1325d9b1-9a29-44b6-b748-55c8f5e196a4"},"outputs":[{"data":{"text/plain":["((141, 8), (29292, 8))"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["valid_df = df[df['img_id'].isin(valid_ids)]\n","train_df = df[df['img_id'].isin(train_ids)]\n","valid_df.shape, train_df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EvCx_P7mg_-k"},"outputs":[],"source":["!pip install -q albumentations\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import numpy as np\n","import os\n","from albumentations import RandomRotate90\n","from tensorflow.keras import mixed_precision\n","import gc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LX7lOczzg_-l"},"outputs":[],"source":["def func(image):\n","    Trgb2lms =np.array( [\n","          np.array([17.8824, 43.5161, 4.1194]),\n","          np.array([3.4557,27.1154, 3.8671]),\n","          np.array([0.0300, 0.1843, 1.4671]) \n","      ])\n","    \n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    x,y,z = image.shape\n","#     print(image.shape)\n","    cvd_due = np.array([\n","                     np.array([1 ,0, 0]),   \n","                     np.array([0.494207, 0, 1.24827]),   \n","                     np.array([0, 0, 1]),   \n","    ])\n","    INV_Trgb2lms = np.linalg.inv(Trgb2lms) \n","\n","#     print(image.transpose(2, 0, 1).shape)\n","    out = np.dot(INV_Trgb2lms, cvd_due)\n","    out = np.dot(out, Trgb2lms)\n","    out = np.dot(out, image.transpose(2, 0, 1).reshape(3,-1)) \n","    out = out.reshape(3,x,y).transpose(1, 2, 0)\n","    out = cv2.cvtColor(np.float32(out), cv2.COLOR_RGB2BGR)\n","\n","    return out\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D-2_NuLkg_-m"},"outputs":[],"source":["class VOCDataset(Dataset):\n","    \n","    def __init__(self, dataframe, image_dir, transforms=None):\n","        super().__init__()\n","        \n","        self.image_ids = dataframe['img_id'].unique()\n","        self.df = dataframe\n","        self.image_dir = image_dir\n","        self.transforms = transforms\n","    \n","    def __getitem__(self, index: int):\n","        image_id = self.image_ids[index]\n","        records = self.df[self.df['img_id'] == image_id]\n","        \n","        image = cv2.imread(f'{self.image_dir}/{image_id}.jpg', cv2.IMREAD_COLOR)\n","        image = func(image)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n","        image /= 255.0\n","        rows, cols = image.shape[:2]\n","        \n","        boxes = records[['xmin', 'ymin', 'xmax', 'ymax']].values\n","        \n","       \n","        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n","        area = torch.as_tensor(area, dtype=torch.float32)\n","        \n","        label = records['labels'].values\n","        labels = torch.as_tensor(label, dtype=torch.int64)\n","        \n","        # suppose all instances are not crowd\n","        iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n","        \n","        target = {}\n","        target['boxes'] = boxes\n","        target['labels'] = labels\n","        # target['masks'] = None\n","        target['image_id'] = torch.tensor([index])\n","        target['area'] = area\n","        target['iscrowd'] = iscrowd\n","        \n","        if self.transforms:\n","            sample = {\n","                'image': image,\n","                'bboxes': target['boxes'],\n","                'labels': labels\n","            }\n","            sample = self.transforms(**sample)\n","            image = sample['image']\n","            \n","            target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1,0)\n","            \n","            return image, target\n","        \n","    def __len__(self) -> int:\n","        return self.image_ids.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h3-oAySag_-n"},"outputs":[],"source":["def get_transform_train():\n","    return A.Compose([\n","        A.HorizontalFlip(p=0.5),\n","        A.RandomBrightnessContrast(p=0.2),\n","        ToTensorV2(p=1.0)\n","    ], bbox_params={'format':'pascal_voc', 'label_fields': ['labels']})\n","\n","def get_transform_valid():\n","    return A.Compose([\n","        ToTensorV2(p=1.0)\n","    ], bbox_params={'format': 'pascal_voc', 'label_fields':['labels']})"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1680950282385,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"cfWNyTMWg_-n","outputId":"cca64814-c846-4c79-b8e4-117a67d2f92b"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["def collate_fn(batch):\n","    return tuple(zip(*batch))\n","\n","train_dataset = VOCDataset(train_df, IMG_PATH , get_transform_train())\n","valid_dataset = VOCDataset(valid_df, IMG_PATH, get_transform_valid())\n","\n","\n","# split the dataset in train and test set\n","indices = torch.randperm(len(train_dataset)).tolist()\n","\n","\n","train_data_loader = DataLoader(\n","    train_dataset,\n","    batch_size=4,\n","    shuffle=True,\n","    num_workers=4,\n","    collate_fn=collate_fn\n",")\n","\n","valid_data_loader = DataLoader(\n","    valid_dataset,\n","    batch_size=4,\n","    shuffle=False,\n","    num_workers=4,\n","    collate_fn=collate_fn\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VV2IexHNg_-o"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","output_embedded_package_id":"1ztzlJymufM-G6Bt1OWLrMCKHdMFCqinC"},"id":"DIdYOvrkg_-o","outputId":"2d318242-7a42-433b-8dcd-6a5af9705a58"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["images, targets= next(iter(train_data_loader))\n","images = list(image.to(device) for image in images)\n","targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","plt.figure(figsize=(20,20))\n","for i, (image, target) in enumerate(zip(images, targets)):\n","    plt.subplot(2,2, i+1)\n","    boxes = targets[i]['boxes'].cpu().numpy().astype(np.int32)\n","    sample = images[i].permute(1,2,0).cpu().numpy()\n","    names = targets[i]['labels'].cpu().numpy().astype(np.int64)\n","    for i,box in enumerate(boxes):\n","        cv2.rectangle(sample,\n","                      (box[0], box[1]),\n","                      (box[2], box[3]),\n","                      (0, 0, 220), 2)\n","        cv2.putText(sample, classes[names[i]], (box[0],box[1]+15),cv2.FONT_HERSHEY_COMPLEX ,0.5,(0,220,0),1,cv2.LINE_AA)  \n","\n","    plt.axis('off')\n","    plt.imshow(sample)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3148,"status":"ok","timestamp":1680937697558,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"MZuDSLpIg_-p","outputId":"21e4e9e5-f1fb-49ef-8e94-6e3e33c3d1c5"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n","100%|██████████| 160M/160M [00:01<00:00, 102MB/s] \n"]}],"source":["# load a model; pre-trained on COCO\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ovW_8cxmg_-p"},"outputs":[],"source":["num_classes = 12\n","\n","# get number of input features for the classifier\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","\n","# replace the pre-trained head with a new one\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"CavTpFzNg_-q"},"outputs":[],"source":["model.to(device)\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005, weight_decay=0.0005)\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16079,"status":"ok","timestamp":1680937732139,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"4JyxrgvJg_-q","outputId":"502efd44-cda8-4d28-e1ce-a19bf229d811"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n","  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-qat4t650\n","  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-qat4t650\n","  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.9/dist-packages (from pycocotools==2.0) (67.6.1)\n","Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.9/dist-packages (from pycocotools==2.0) (0.29.34)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from pycocotools==2.0) (3.7.1)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (5.12.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (4.39.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.0.7)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (23.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (8.4.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.22.4)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.11.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=2.1.0->pycocotools==2.0) (3.15.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0) (1.16.0)\n","Building wheels for collected packages: pycocotools\n","  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycocotools: filename=pycocotools-2.0-cp39-cp39-linux_x86_64.whl size=397992 sha256=22fddc9a9ea41a30af69a5d5d8301b136023e9566c20f0242ac55d72752ccbf7\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-bb844oqw/wheels/13/c1/d6/a321055f7089f1a6af654fbf794536b196999f082a9cb68a37\n","Successfully built pycocotools\n","Installing collected packages: pycocotools\n","  Attempting uninstall: pycocotools\n","    Found existing installation: pycocotools 2.0.6\n","    Uninstalling pycocotools-2.0.6:\n","      Successfully uninstalled pycocotools-2.0.6\n","Successfully installed pycocotools-2.0\n"]}],"source":["!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":107330,"status":"ok","timestamp":1680937843050,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"kKqulq9Lg_-r","outputId":"6dff8dde-3bc1-4571-d50c-93468763103b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'vision'...\n","remote: Enumerating objects: 322005, done.\u001b[K\n","remote: Counting objects: 100% (5027/5027), done.\u001b[K\n","remote: Compressing objects: 100% (585/585), done.\u001b[K\n","remote: Total 322005 (delta 4596), reused 4828 (delta 4433), pack-reused 316978\u001b[K\n","Receiving objects: 100% (322005/322005), 653.96 MiB | 14.74 MiB/s, done.\n","Resolving deltas: 100% (295941/295941), done.\n","Updating files: 100% (890/890), done.\n"]}],"source":["!git clone https://github.com/pytorch/vision.git\n","!cd vision;cp references/detection/utils.py ../;cp references/detection/transforms.py ../;cp references/detection/coco_eval.py ../;cp references/detection/engine.py ../;cp references/detection/coco_utils.py ../"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VggsFCZ5g_-r"},"outputs":[],"source":["from engine import train_one_epoch, evaluate\n","import utils"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":322709,"status":"ok","timestamp":1680938188463,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"K-Idxjreg_-r","outputId":"3eef3413-43a1-40c4-fe16-889ade42e6a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: [0]  [  0/245]  eta: 1:12:50  lr: 0.000025  loss: 3.8702 (3.8702)  loss_classifier: 2.4948 (2.4948)  loss_box_reg: 0.6214 (0.6214)  loss_objectness: 0.5629 (0.5629)  loss_rpn_box_reg: 0.1911 (0.1911)  time: 17.8373  data: 6.4058  max mem: 4272\n","Epoch: [0]  [ 10/245]  eta: 0:10:30  lr: 0.000230  loss: 3.7137 (3.6533)  loss_classifier: 2.4708 (2.4601)  loss_box_reg: 0.5316 (0.5791)  loss_objectness: 0.2612 (0.3956)  loss_rpn_box_reg: 0.2063 (0.2185)  time: 2.6820  data: 0.6728  max mem: 5060\n","Epoch: [0]  [ 20/245]  eta: 0:07:28  lr: 0.000435  loss: 3.3297 (3.4644)  loss_classifier: 2.3019 (2.2674)  loss_box_reg: 0.5316 (0.5666)  loss_objectness: 0.2624 (0.4191)  loss_rpn_box_reg: 0.1848 (0.2112)  time: 1.2008  data: 0.1002  max mem: 5060\n","Epoch: [0]  [ 30/245]  eta: 0:06:15  lr: 0.000640  loss: 2.8273 (3.1697)  loss_classifier: 1.6908 (2.0115)  loss_box_reg: 0.5783 (0.5827)  loss_objectness: 0.2578 (0.3615)  loss_rpn_box_reg: 0.1713 (0.2139)  time: 1.2326  data: 0.1055  max mem: 5060\n","Epoch: [0]  [ 40/245]  eta: 0:05:32  lr: 0.000844  loss: 2.3035 (2.8765)  loss_classifier: 1.2089 (1.7479)  loss_box_reg: 0.5989 (0.5857)  loss_objectness: 0.1953 (0.3266)  loss_rpn_box_reg: 0.1959 (0.2163)  time: 1.2371  data: 0.1156  max mem: 5060\n","Epoch: [0]  [ 50/245]  eta: 0:05:04  lr: 0.001049  loss: 1.7421 (2.6342)  loss_classifier: 0.7695 (1.5380)  loss_box_reg: 0.5915 (0.5839)  loss_objectness: 0.1612 (0.3001)  loss_rpn_box_reg: 0.2065 (0.2123)  time: 1.2780  data: 0.1178  max mem: 6313\n","Epoch: [0]  [ 60/245]  eta: 0:04:37  lr: 0.001254  loss: 1.4681 (2.4330)  loss_classifier: 0.5604 (1.3680)  loss_box_reg: 0.5531 (0.5791)  loss_objectness: 0.1484 (0.2750)  loss_rpn_box_reg: 0.1830 (0.2109)  time: 1.2525  data: 0.1062  max mem: 6313\n","Epoch: [0]  [ 70/245]  eta: 0:04:16  lr: 0.001458  loss: 1.3661 (2.2789)  loss_classifier: 0.4809 (1.2370)  loss_box_reg: 0.5482 (0.5717)  loss_objectness: 0.1501 (0.2604)  loss_rpn_box_reg: 0.1995 (0.2098)  time: 1.2157  data: 0.1017  max mem: 6313\n","Epoch: [0]  [ 80/245]  eta: 0:03:57  lr: 0.001663  loss: 1.2570 (2.1481)  loss_classifier: 0.4171 (1.1297)  loss_box_reg: 0.5292 (0.5628)  loss_objectness: 0.1677 (0.2481)  loss_rpn_box_reg: 0.2041 (0.2075)  time: 1.2397  data: 0.1036  max mem: 6313\n","Epoch: [0]  [ 90/245]  eta: 0:03:39  lr: 0.001868  loss: 1.2452 (2.0542)  loss_classifier: 0.3495 (1.0460)  loss_box_reg: 0.5319 (0.5600)  loss_objectness: 0.1466 (0.2381)  loss_rpn_box_reg: 0.2050 (0.2101)  time: 1.2353  data: 0.1005  max mem: 6313\n","Epoch: [0]  [100/245]  eta: 0:03:22  lr: 0.002073  loss: 1.2723 (1.9723)  loss_classifier: 0.3482 (0.9774)  loss_box_reg: 0.5331 (0.5564)  loss_objectness: 0.1466 (0.2293)  loss_rpn_box_reg: 0.2120 (0.2093)  time: 1.2306  data: 0.0908  max mem: 6313\n","Epoch: [0]  [110/245]  eta: 0:03:06  lr: 0.002277  loss: 1.2464 (1.8982)  loss_classifier: 0.3213 (0.9188)  loss_box_reg: 0.5331 (0.5486)  loss_objectness: 0.1474 (0.2224)  loss_rpn_box_reg: 0.2120 (0.2084)  time: 1.2381  data: 0.0964  max mem: 6313\n","Epoch: [0]  [120/245]  eta: 0:02:51  lr: 0.002482  loss: 1.1363 (1.8348)  loss_classifier: 0.3170 (0.8688)  loss_box_reg: 0.4672 (0.5438)  loss_objectness: 0.1251 (0.2134)  loss_rpn_box_reg: 0.2051 (0.2088)  time: 1.2273  data: 0.1008  max mem: 6313\n","Epoch: [0]  [130/245]  eta: 0:02:36  lr: 0.002687  loss: 1.1558 (1.7824)  loss_classifier: 0.3101 (0.8258)  loss_box_reg: 0.4849 (0.5377)  loss_objectness: 0.1175 (0.2091)  loss_rpn_box_reg: 0.2272 (0.2098)  time: 1.2180  data: 0.0953  max mem: 6313\n","Epoch: [0]  [140/245]  eta: 0:02:21  lr: 0.002891  loss: 1.0810 (1.7317)  loss_classifier: 0.2899 (0.7879)  loss_box_reg: 0.4604 (0.5294)  loss_objectness: 0.1423 (0.2044)  loss_rpn_box_reg: 0.2202 (0.2100)  time: 1.2280  data: 0.0941  max mem: 6313\n","Epoch: [0]  [150/245]  eta: 0:02:07  lr: 0.003096  loss: 1.0603 (1.6847)  loss_classifier: 0.2871 (0.7552)  loss_box_reg: 0.4107 (0.5205)  loss_objectness: 0.1312 (0.1992)  loss_rpn_box_reg: 0.1986 (0.2099)  time: 1.2441  data: 0.0900  max mem: 6313\n","Epoch: [0]  [160/245]  eta: 0:01:53  lr: 0.003301  loss: 1.0650 (1.6475)  loss_classifier: 0.2904 (0.7273)  loss_box_reg: 0.4072 (0.5145)  loss_objectness: 0.1149 (0.1960)  loss_rpn_box_reg: 0.1986 (0.2097)  time: 1.2497  data: 0.0883  max mem: 6313\n","Epoch: [0]  [170/245]  eta: 0:01:39  lr: 0.003506  loss: 1.0417 (1.6108)  loss_classifier: 0.2910 (0.7022)  loss_box_reg: 0.4214 (0.5093)  loss_objectness: 0.1203 (0.1915)  loss_rpn_box_reg: 0.1619 (0.2076)  time: 1.2511  data: 0.0902  max mem: 6313\n","Epoch: [0]  [180/245]  eta: 0:01:26  lr: 0.003710  loss: 1.0035 (1.5799)  loss_classifier: 0.2780 (0.6793)  loss_box_reg: 0.4357 (0.5066)  loss_objectness: 0.1192 (0.1873)  loss_rpn_box_reg: 0.1746 (0.2067)  time: 1.2226  data: 0.0833  max mem: 6313\n","Epoch: [0]  [190/245]  eta: 0:01:12  lr: 0.003915  loss: 0.9890 (1.5481)  loss_classifier: 0.2670 (0.6582)  loss_box_reg: 0.4139 (0.5000)  loss_objectness: 0.1293 (0.1849)  loss_rpn_box_reg: 0.1739 (0.2050)  time: 1.2011  data: 0.0780  max mem: 6313\n","Epoch: [0]  [200/245]  eta: 0:00:59  lr: 0.004120  loss: 1.0117 (1.5262)  loss_classifier: 0.2841 (0.6406)  loss_box_reg: 0.4244 (0.4991)  loss_objectness: 0.1111 (0.1813)  loss_rpn_box_reg: 0.2026 (0.2051)  time: 1.2370  data: 0.0908  max mem: 6313\n","Epoch: [0]  [210/245]  eta: 0:00:45  lr: 0.004324  loss: 1.0635 (1.5043)  loss_classifier: 0.2936 (0.6235)  loss_box_reg: 0.4395 (0.4965)  loss_objectness: 0.1181 (0.1796)  loss_rpn_box_reg: 0.2118 (0.2047)  time: 1.2628  data: 0.1017  max mem: 6313\n","Epoch: [0]  [220/245]  eta: 0:00:32  lr: 0.004529  loss: 1.0566 (1.4824)  loss_classifier: 0.2900 (0.6079)  loss_box_reg: 0.4131 (0.4921)  loss_objectness: 0.1181 (0.1760)  loss_rpn_box_reg: 0.2187 (0.2063)  time: 1.2587  data: 0.0987  max mem: 6313\n","Epoch: [0]  [230/245]  eta: 0:00:19  lr: 0.004734  loss: 1.0333 (1.4658)  loss_classifier: 0.2934 (0.5945)  loss_box_reg: 0.3999 (0.4895)  loss_objectness: 0.1179 (0.1748)  loss_rpn_box_reg: 0.2324 (0.2070)  time: 1.2521  data: 0.0878  max mem: 6313\n","Epoch: [0]  [240/245]  eta: 0:00:06  lr: 0.004939  loss: 1.0072 (1.4448)  loss_classifier: 0.2808 (0.5812)  loss_box_reg: 0.4163 (0.4844)  loss_objectness: 0.1337 (0.1736)  loss_rpn_box_reg: 0.1929 (0.2057)  time: 1.2187  data: 0.0732  max mem: 6313\n","Epoch: [0]  [244/245]  eta: 0:00:01  lr: 0.005000  loss: 0.9907 (1.4386)  loss_classifier: 0.2866 (0.5764)  loss_box_reg: 0.3946 (0.4827)  loss_objectness: 0.1362 (0.1734)  loss_rpn_box_reg: 0.1929 (0.2060)  time: 1.1708  data: 0.0638  max mem: 6313\n","Epoch: [0] Total time: 0:05:18 (1.2981 s / it)\n","creating index...\n","index created!\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Test:  [0/1]  eta: 0:00:01  model_time: 0.4537 (0.4537)  evaluator_time: 0.2736 (0.2736)  time: 1.9105  data: 1.1457  max mem: 6313\n","Test: Total time: 0:00:02 (2.0365 s / it)\n","Averaged stats: model_time: 0.4537 (0.4537)  evaluator_time: 0.2736 (0.2736)\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n","IoU metric: bbox\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.141\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.253\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.148\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.024\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.142\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.735\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.012\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.099\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.167\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.070\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.167\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.767\n","CPU times: user 2min 26s, sys: 11.5 s, total: 2min 37s\n","Wall time: 5min 21s\n"]}],"source":["%%time\n","# let's train it for 1 epoch\n","num_epochs = 1\n","\n","for epoch in range(num_epochs):\n","    # train for one epoch, printing every 10 iterations\n","    train_one_epoch(model, optimizer, train_data_loader, device, epoch, print_freq=10)\n","    # update the learning rate\n","    lr_scheduler.step()\n","    # evaluate on the test dataset\n","    evaluate(model, valid_data_loader, device=device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M8oQFNLMg_-s"},"outputs":[],"source":["torch.save(model.state_dict(), 'faster_rcnn_state.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1275,"status":"ok","timestamp":1680938211759,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"b-G2lTWRg_-s","outputId":"49b9dad4-143d-4507-9863-27d8a571eb60"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained_backbone' is deprecated since 0.13 and may be removed in the future, please use 'weights_backbone' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights_backbone' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights_backbone=None`.\n","  warnings.warn(msg)\n"]}],"source":["# load  a model; pre-trained on COCO\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, pretrained_backbone=False)\n","\n","WEIGHTS_FILE = \"./faster_rcnn_state.pth\"\n","\n","num_classes = 12\n","\n","# get number of input features for the classifier\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","\n","# replace the pre-trained head with a new one\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","# Load the traines weights\n","model.load_state_dict(torch.load(WEIGHTS_FILE))\n","\n","model = model.to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ISQInM55g_-t"},"outputs":[],"source":["def obj_detector(img):\n","    img = cv2.imread(img, cv2.IMREAD_COLOR)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n","\n","\n","    img /= 255.0\n","    img = torch.from_numpy(img)\n","    img = img.unsqueeze(0)\n","    img = img.permute(0,3,1,2)\n","    \n","    model.eval()\n","\n","    detection_threshold = 0.70\n","    \n","    img = list(im.to(device) for im in img)\n","    output = model(img)\n","\n","    for i , im in enumerate(img):\n","        boxes = output[i]['boxes'].data.cpu().numpy()\n","        scores = output[i]['scores'].data.cpu().numpy()\n","        labels = output[i]['labels'].data.cpu().numpy()\n","\n","        labels = labels[scores >= detection_threshold]\n","        boxes = boxes[scores >= detection_threshold].astype(np.int32)\n","        scores = scores[scores >= detection_threshold]\n","\n","        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n","        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n","    \n","    sample = img[0].permute(1,2,0).cpu().numpy()\n","    sample = np.array(sample)\n","    boxes = output[0]['boxes'].data.cpu().numpy()\n","    name = output[0]['labels'].data.cpu().numpy()\n","    scores = output[0]['scores'].data.cpu().numpy()\n","    boxes = boxes[scores >= detection_threshold].astype(np.int32)\n","    names = name.tolist()\n","    \n","    return names, boxes, sample"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13604,"status":"ok","timestamp":1680952841115,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"rlpYQbaDg_-t","outputId":"9b5b9ab3-3098-4d99-e7fd-7caffa60859d"},"outputs":[{"output_type":"stream","name":"stdout","text":["0 ./test/0000007_05999_d_0000038.jpg\n","1 ./test/0000002_00005_d_0000014.jpg\n","2 ./test/0000072_00000_d_0000001.jpg\n","3 ./test/0000107_02196_d_0000055.jpg\n","4 ./test/0000072_07660_d_0000012.jpg\n","5 ./test/0000008_00889_d_0000039.jpg\n","6 ./test/0000008_03499_d_0000043.jpg\n","7 ./test/0000008_03999_d_0000044.jpg\n","8 ./test/0000008_04499_d_0000045.jpg\n","9 ./test/0000008_02999_d_0000042.jpg\n","10 ./test/0000008_02499_d_0000041.jpg\n","11 ./test/0000008_01999_d_0000040.jpg\n","12 ./test/0000036_00500_d_0000046.jpg\n","13 ./test/0000031_02000_d_0000041.jpg\n","14 ./test/0000031_03527_d_0000043.jpg\n","15 ./test/0000031_00000_d_0000037.jpg\n","16 ./test/9999999_00301_d_0000133.jpg\n","17 ./test/9999999_00299_d_0000132.jpg\n","18 ./test/0000040_04284_d_0000071.jpg\n","19 ./test/0000040_02454_d_0000068.jpg\n","20 ./test/0000040_03288_d_0000069.jpg\n","21 ./test/0000040_03752_d_0000070.jpg\n","22 ./test/0000040_01500_d_0000067.jpg\n","23 ./test/0000040_01000_d_0000066.jpg\n","24 ./test/0000039_05300_d_0000061.jpg\n","25 ./test/0000039_00000_d_0000055.jpg\n","26 ./test/0000037_01494_d_0000052.jpg\n","27 ./test/0000039_05625_d_0000062.jpg\n","28 ./test/0000036_03591_d_0000048.jpg\n","29 ./test/9999999_00330_d_0000144.jpg\n","30 ./test/9999999_00332_d_0000145.jpg\n","31 ./test/9999999_00328_d_0000143.jpg\n","32 ./test/9999999_00326_d_0000142.jpg\n","33 ./test/9999999_00322_d_0000141.jpg\n","34 ./test/9999999_00320_d_0000140.jpg\n","35 ./test/9999999_00318_d_0000139.jpg\n","36 ./test/9999999_00313_d_0000138.jpg\n","37 ./test/9999999_00309_d_0000137.jpg\n","38 ./test/9999999_00307_d_0000136.jpg\n","39 ./test/9999999_00303_d_0000134.jpg\n","40 ./test/9999999_00305_d_0000135.jpg\n","41 ./test/9999999_00354_d_0000154.jpg\n","42 ./test/9999999_00356_d_0000155.jpg\n","43 ./test/9999999_00348_d_0000153.jpg\n","44 ./test/9999999_00346_d_0000152.jpg\n","45 ./test/9999999_00342_d_0000150.jpg\n","46 ./test/9999999_00344_d_0000151.jpg\n","47 ./test/9999999_00340_d_0000149.jpg\n","48 ./test/9999999_00338_d_0000148.jpg\n","49 ./test/9999999_00336_d_0000147.jpg\n"]}],"source":["pred_path = \"./test\"\n","pred_files = [os.path.join(pred_path,f) for f in os.listdir(pred_path)]\n","\n","for i, images in enumerate(pred_files):\n","    print(i,images)\n","    names,boxes,sample = obj_detector(images)\n","\n","    img = cv2.imread(images)\n","    \n","    for i,box in enumerate(boxes):\n","        cv2.rectangle(img,\n","                      (box[0], box[1]),\n","                      (box[2], box[3]),\n","                      (0, 220, 0), 2)  \n","\n","    cv2.imwrite(f'./test1/{images[7:]}',img)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1V0y9Jo0CKCAU2vg6hy8V9vHxUauNk0lz","timestamp":1679820769372}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}