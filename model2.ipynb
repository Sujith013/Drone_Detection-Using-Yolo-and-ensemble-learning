{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3233,"status":"ok","timestamp":1680953480354,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"AYTJICU8mTMX","outputId":"39ebbb1c-954f-4270-87d0-adf73b274b0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1680953480355,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"nKm2GBdCmU2s","outputId":"e59e0653-5244-4f86-91d5-8ad7e83bd435"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/data_visualization/datavis_data\n"]}],"source":["cd /content/gdrive/MyDrive/data_visualization/datavis_data/"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"lte9XrLRhFVx","executionInfo":{"status":"ok","timestamp":1680953483841,"user_tz":-330,"elapsed":3490,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["import os\n","import collections\n","import pandas as pd\n","import numpy as np\n","import functools\n","import matplotlib.pyplot as plt\n","import cv2\n","\n","from sklearn import preprocessing \n","\n","\n","import xml.etree.ElementTree as ET\n","\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2\n","\n","import torch\n","import torchvision\n","\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection import FasterRCNN\n","from torchvision.models.detection.rpn import AnchorGenerator\n","\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.data import SequentialSampler"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":632,"status":"ok","timestamp":1680953485077,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"8oUILFDVg_-P","outputId":"7ff4b2b5-ca26-4f86-9d38-6932c50d17cb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{},"execution_count":4}],"source":["XML_PATH = \"annotation\"\n","IMG_PATH = \"train\"\n","XML_FILES = [os.path.join(XML_PATH, f) for f in os.listdir(XML_PATH)]\n","XML_FILES = XML_FILES[:1000] #first 1000\n","\n","len(XML_FILES)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"O_U86BV5g_-Z","executionInfo":{"status":"ok","timestamp":1680953486176,"user_tz":-330,"elapsed":4,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["class XmlParser(object):\n","\n","    def __init__(self,xml_file):\n","\n","        self.xml_file = self.filter(xml_file)\n","        \n","        # path to the image file = name of annotation file\n","        self.img_name = xml_file.split('/')[1].split('.')[0]+\".jpg\";\n","        self.img_path = os.path.join(IMG_PATH, self.img_name)\n","\n","        # image id \n","        self.image_id = self.img_name.split('.')[0];\n","\n","        # names of the classes contained in the xml file\n","        self.names = self._get_names()\n","        # coordinates of the bounding boxes\n","        self.boxes = self._get_bndbox()\n","\n","    def filter(self,xml_file):\n","\n","        filtered_data = []\n","\n","        f = open(xml_file, 'r')\n","\n","        for line in f:\n","            data = line.split(',')\n","            if data[5]!='0' and (data[5]=='1' or data[5]=='2'):\n","                data = [int(x.strip()) for x in data]\n","                filtered_data.append(data)\n","\n","                #augmentation for people\n","                if data[5]=='1' or data[5]=='2':\n","                  filtered_data.append(data)\n","\n","        return filtered_data\n","\n","    def _get_names(self):\n","\n","        label_dict = {\n","                      0 : \"Ignore\",\n","                      1 : \"Pedestrian\",\n","                      2 : \"People\",\n","                      3 : \"Bicycle\",\n","                      4 : \"Car\",\n","                      5 : \"Van\",\n","                      6 : \"Truck\",\n","                      7 : \"Tricycle\",\n","                      8 : \"Awning-tricycle\",\n","                      9 : \"Bus\",\n","                      10 : \"Motor\",\n","                      11 : \"Others\"\n","                    }\n","\n","        names = []\n","\n","        for data in self.xml_file:\n","              class_id = data[5]\n","              names.append(label_dict[class_id])\n","\n","        return np.array(names)\n","\n","    def _get_bndbox(self):\n","\n","        boxes = []\n","\n","        for data in self.xml_file:\n","            \n","            coordinates = []\n","            coordinates.append(np.int32(data[0])) #xmin\n","            coordinates.append(np.int32(np.float32(data[1]))) #ymin\n","            coordinates.append(np.int32(data[2]+data[0])) #xmax\n","            coordinates.append(np.int32(data[3]+data[1])) #ymax\n","            boxes.append(coordinates)\n","\n","        return np.array(boxes)\n","\n","# xml = XmlParser('Annotations/0000007_05999_d_0000038.txt')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10123,"status":"ok","timestamp":1680953500199,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"_NvoeGhmi6Rh","outputId":"9f24da5b-bef7-4721-f270-a980126a868b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["18082"]},"metadata":{},"execution_count":6}],"source":["def xml_files_to_df(xml_files):\n","    \n","    \"\"\"\"Return pandas dataframe from list of XML files.\"\"\"\n","    \n","    names = []\n","    boxes = []\n","    image_id = []\n","    xml_path = []\n","    img_path = []\n","    for file in xml_files:\n","        xml = XmlParser(file)\n","        names.extend(xml.names)\n","        boxes.extend(xml.boxes)\n","        image_id.extend([xml.image_id] * len(xml.names))\n","        xml_path.extend([xml.xml_file] * len(xml.names))\n","        img_path.extend([xml.img_path] * len(xml.names))\n","    a = {\"img_id\": image_id,\n","         \"names\": names,\n","         \"boxes\": boxes,\n","         \"xml_path\":xml_path,\n","         \"img_path\":img_path}\n","    \n","    df = pd.DataFrame.from_dict(a, orient='index')\n","    df = df.transpose()\n","    \n","    return df\n","\n","df = xml_files_to_df(XML_FILES)\n","df.head()\n","df.shape[0]"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1680953501225,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"UL91oDD4g_-c","outputId":"18c625d8-cd0f-4eba-cd27-59779e92c120"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pedestrian    13445\n","People         4637\n","Name: names, dtype: int64"]},"metadata":{},"execution_count":7}],"source":["# check values for per class\n","df['names'].value_counts()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1680953501226,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"Ui-v8WIHg_-d","outputId":"cc1ef2b3-3ac0-4015-c9a1-bddbc17895d8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0          [873, 451, 890, 473]\n","1          [754, 376, 761, 384]\n","2          [796, 305, 801, 310]\n","3          [836, 283, 840, 288]\n","4        [1291, 160, 1311, 190]\n","                  ...          \n","18077     [1499, 94, 1504, 108]\n","18078     [1489, 95, 1495, 108]\n","18079      [1688, 62, 1693, 76]\n","18080      [1678, 59, 1684, 73]\n","18081      [1655, 31, 1660, 42]\n","Name: boxes, Length: 18082, dtype: object"]},"metadata":{},"execution_count":8}],"source":["df['boxes']"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":751,"status":"ok","timestamp":1680953501973,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"D_sTTUxBg_-e","outputId":"540c24b4-047f-486e-f774-87a4589aecfc"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py:3473: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  if (await self.run_code(code, result,  async_=asy)):\n"]}],"source":["# classes need to be in int form so we use LabelEncoder for this task\n","enc = preprocessing.LabelEncoder()\n","df['labels'] = enc.fit_transform(df['names'])\n","df['labels'] = np.stack(df['labels'][i]+1 for i in range(len(df['labels']))) "]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1680953501974,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"byc5kANsg_-f","outputId":"1373f97f-cb59-4f48-9eb6-7809c884b956"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["names       labels\n","Pedestrian  1         13445\n","People      2          4637\n","dtype: int64"]},"metadata":{},"execution_count":10}],"source":["classes = df[['names','labels']].value_counts()\n","classes"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1680953501976,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"9a-7b1bKsj89","outputId":"b0e8acec-ca9e-4379-d429-75f86ec4e8af"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                    img_id       names                   boxes  \\\n","0  9999994_00000_d_0000055  Pedestrian    [873, 451, 890, 473]   \n","1  9999994_00000_d_0000055  Pedestrian    [754, 376, 761, 384]   \n","2  9999994_00000_d_0000055  Pedestrian    [796, 305, 801, 310]   \n","3  9999994_00000_d_0000055      People    [836, 283, 840, 288]   \n","4  9999994_00000_d_0000055      People  [1291, 160, 1311, 190]   \n","\n","                                            xml_path  \\\n","0  [[873, 451, 17, 22, 1, 1, 0, 2], [754, 376, 7,...   \n","1  [[873, 451, 17, 22, 1, 1, 0, 2], [754, 376, 7,...   \n","2  [[873, 451, 17, 22, 1, 1, 0, 2], [754, 376, 7,...   \n","3  [[873, 451, 17, 22, 1, 1, 0, 2], [754, 376, 7,...   \n","4  [[873, 451, 17, 22, 1, 1, 0, 2], [754, 376, 7,...   \n","\n","                            img_path  labels  \n","0  train/9999994_00000_d_0000055.jpg       1  \n","1  train/9999994_00000_d_0000055.jpg       1  \n","2  train/9999994_00000_d_0000055.jpg       1  \n","3  train/9999994_00000_d_0000055.jpg       2  \n","4  train/9999994_00000_d_0000055.jpg       2  "],"text/html":["\n","  <div id=\"df-22af5621-9412-41a7-902c-f41bb0be998f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>img_id</th>\n","      <th>names</th>\n","      <th>boxes</th>\n","      <th>xml_path</th>\n","      <th>img_path</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>Pedestrian</td>\n","      <td>[873, 451, 890, 473]</td>\n","      <td>[[873, 451, 17, 22, 1, 1, 0, 2], [754, 376, 7,...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>Pedestrian</td>\n","      <td>[754, 376, 761, 384]</td>\n","      <td>[[873, 451, 17, 22, 1, 1, 0, 2], [754, 376, 7,...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>Pedestrian</td>\n","      <td>[796, 305, 801, 310]</td>\n","      <td>[[873, 451, 17, 22, 1, 1, 0, 2], [754, 376, 7,...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>People</td>\n","      <td>[836, 283, 840, 288]</td>\n","      <td>[[873, 451, 17, 22, 1, 1, 0, 2], [754, 376, 7,...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>People</td>\n","      <td>[1291, 160, 1311, 190]</td>\n","      <td>[[873, 451, 17, 22, 1, 1, 0, 2], [754, 376, 7,...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22af5621-9412-41a7-902c-f41bb0be998f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-22af5621-9412-41a7-902c-f41bb0be998f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-22af5621-9412-41a7-902c-f41bb0be998f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}],"source":["df.head()"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"ZPxyczp5g_-g","executionInfo":{"status":"ok","timestamp":1680953501976,"user_tz":-330,"elapsed":9,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["classes = {\n","                      1 : \"Pedestrian\",\n","                      2 : \"People\",\n","                    }"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":560,"status":"ok","timestamp":1680953503823,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"NFVN1DODg_-h","outputId":"2d7bada8-5a4e-4e99-b499-c2ae51e7804a"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py:3473: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  if (await self.run_code(code, result,  async_=asy)):\n"]}],"source":["#bounding box coordinates point need to be in separate columns\n","\n","df['xmin'] = -1\n","df['ymin'] = -1\n","df['xmax'] = -1\n","df['ymax'] = -1\n","\n","df[['xmin','ymin','xmax','ymax']]=np.stack(df['boxes'][i] for i in range(len(df['boxes'])))\n","\n","df.drop(columns=['boxes'], inplace=True)\n","df['xmin'] = df['xmin'].astype(float)\n","df['ymin'] = df['ymin'].astype(float)\n","df['xmax'] = df['xmax'].astype(float)\n","df['ymax'] = df['ymax'].astype(float)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":607,"status":"ok","timestamp":1680953508835,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"OpjbwFXAg_-i","outputId":"99126db7-ca5f-44bb-bf35-fcccbf929205"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                    img_id                                           xml_path  \\\n","0  9999994_00000_d_0000055  [[873, 451, 17, 22, 1, 1, 0, 2], [754, 376, 7,...   \n","1  9999994_00000_d_0000055  [[873, 451, 17, 22, 1, 1, 0, 2], [754, 376, 7,...   \n","2  9999994_00000_d_0000055  [[873, 451, 17, 22, 1, 1, 0, 2], [754, 376, 7,...   \n","3  9999994_00000_d_0000055  [[873, 451, 17, 22, 1, 1, 0, 2], [754, 376, 7,...   \n","4  9999994_00000_d_0000055  [[873, 451, 17, 22, 1, 1, 0, 2], [754, 376, 7,...   \n","\n","                            img_path  labels    xmin   ymin    xmax   ymax  \n","0  train/9999994_00000_d_0000055.jpg       1   873.0  451.0   890.0  473.0  \n","1  train/9999994_00000_d_0000055.jpg       1   754.0  376.0   761.0  384.0  \n","2  train/9999994_00000_d_0000055.jpg       1   796.0  305.0   801.0  310.0  \n","3  train/9999994_00000_d_0000055.jpg       2   836.0  283.0   840.0  288.0  \n","4  train/9999994_00000_d_0000055.jpg       2  1291.0  160.0  1311.0  190.0  "],"text/html":["\n","  <div id=\"df-a26ddfa7-2ee6-4954-b27a-57731ca4cc98\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>img_id</th>\n","      <th>xml_path</th>\n","      <th>img_path</th>\n","      <th>labels</th>\n","      <th>xmin</th>\n","      <th>ymin</th>\n","      <th>xmax</th>\n","      <th>ymax</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>[[873, 451, 17, 22, 1, 1, 0, 2], [754, 376, 7,...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>1</td>\n","      <td>873.0</td>\n","      <td>451.0</td>\n","      <td>890.0</td>\n","      <td>473.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>[[873, 451, 17, 22, 1, 1, 0, 2], [754, 376, 7,...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>1</td>\n","      <td>754.0</td>\n","      <td>376.0</td>\n","      <td>761.0</td>\n","      <td>384.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>[[873, 451, 17, 22, 1, 1, 0, 2], [754, 376, 7,...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>1</td>\n","      <td>796.0</td>\n","      <td>305.0</td>\n","      <td>801.0</td>\n","      <td>310.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>[[873, 451, 17, 22, 1, 1, 0, 2], [754, 376, 7,...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","      <td>836.0</td>\n","      <td>283.0</td>\n","      <td>840.0</td>\n","      <td>288.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9999994_00000_d_0000055</td>\n","      <td>[[873, 451, 17, 22, 1, 1, 0, 2], [754, 376, 7,...</td>\n","      <td>train/9999994_00000_d_0000055.jpg</td>\n","      <td>2</td>\n","      <td>1291.0</td>\n","      <td>160.0</td>\n","      <td>1311.0</td>\n","      <td>190.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a26ddfa7-2ee6-4954-b27a-57731ca4cc98')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a26ddfa7-2ee6-4954-b27a-57731ca4cc98 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a26ddfa7-2ee6-4954-b27a-57731ca4cc98');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}],"source":["# drop names column since we dont need it anymore\n","df.drop(columns=['names'], inplace=True)\n","df.head()"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1680953510974,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"m7RqwLzZg_-j","outputId":"11e37964-4076-4d26-ed55-b120affb7e8b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["940"]},"metadata":{},"execution_count":15}],"source":["len(df['img_id'].unique())"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1680953511489,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"JYr0ORPlg_-j","outputId":"31f50ccc-7027-485d-d0f7-385e9bbe7000"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["936"]},"metadata":{},"execution_count":16}],"source":["image_ids = df['img_id'].unique()\n","valid_ids = image_ids[-4:]\n","train_ids = image_ids[:-4]\n","len(train_ids)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":473,"status":"ok","timestamp":1680953513998,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"W96Vu4Hpg_-k","outputId":"18bca300-39c3-4aac-8f2c-b681cc1cbaa0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((121, 8), (17961, 8))"]},"metadata":{},"execution_count":17}],"source":["valid_df = df[df['img_id'].isin(valid_ids)]\n","train_df = df[df['img_id'].isin(train_ids)]\n","valid_df.shape, train_df.shape"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"EvCx_P7mg_-k","executionInfo":{"status":"ok","timestamp":1680953522649,"user_tz":-330,"elapsed":6859,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["!pip install -q albumentations\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import numpy as np\n","import os\n","from albumentations import RandomRotate90\n","from tensorflow.keras import mixed_precision\n","import gc"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"LX7lOczzg_-l","executionInfo":{"status":"ok","timestamp":1680953523982,"user_tz":-330,"elapsed":5,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["def func(image):\n","    Trgb2lms =np.array( [\n","          np.array([17.8824, 43.5161, 4.1194]),\n","          np.array([3.4557,27.1154, 3.8671]),\n","          np.array([0.0300, 0.1843, 1.4671]) \n","      ])\n","    \n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    x,y,z = image.shape\n","#     print(image.shape)\n","    cvd_due = np.array([\n","                     np.array([1 ,0, 0]),   \n","                     np.array([0.494207, 0, 1.24827]),   \n","                     np.array([0, 0, 1]),   \n","    ])\n","    INV_Trgb2lms = np.linalg.inv(Trgb2lms) \n","\n","#     print(image.transpose(2, 0, 1).shape)\n","    out = np.dot(INV_Trgb2lms, cvd_due)\n","    out = np.dot(out, Trgb2lms)\n","    out = np.dot(out, image.transpose(2, 0, 1).reshape(3,-1)) \n","    out = out.reshape(3,x,y).transpose(1, 2, 0)\n","    out = cv2.cvtColor(np.float32(out), cv2.COLOR_RGB2BGR)\n","\n","    return out\n","  "]},{"cell_type":"code","execution_count":20,"metadata":{"id":"D-2_NuLkg_-m","executionInfo":{"status":"ok","timestamp":1680953523983,"user_tz":-330,"elapsed":5,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["class VOCDataset(Dataset):\n","    \n","    def __init__(self, dataframe, image_dir, transforms=None):\n","        super().__init__()\n","        \n","        self.image_ids = dataframe['img_id'].unique()\n","        self.df = dataframe\n","        self.image_dir = image_dir\n","        self.transforms = transforms\n","    \n","    def __getitem__(self, index: int):\n","        image_id = self.image_ids[index]\n","        records = self.df[self.df['img_id'] == image_id]\n","        \n","        image = cv2.imread(f'{self.image_dir}/{image_id}.jpg', cv2.IMREAD_COLOR)\n","        image = func(image)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n","        image /= 255.0\n","        rows, cols = image.shape[:2]\n","        \n","        boxes = records[['xmin', 'ymin', 'xmax', 'ymax']].values\n","        \n","       \n","        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n","        area = torch.as_tensor(area, dtype=torch.float32)\n","        \n","        label = records['labels'].values\n","        labels = torch.as_tensor(label, dtype=torch.int64)\n","        \n","        # suppose all instances are not crowd\n","        iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n","        \n","        target = {}\n","        target['boxes'] = boxes\n","        target['labels'] = labels\n","        # target['masks'] = None\n","        target['image_id'] = torch.tensor([index])\n","        target['area'] = area\n","        target['iscrowd'] = iscrowd\n","        \n","        if self.transforms:\n","            sample = {\n","                'image': image,\n","                'bboxes': target['boxes'],\n","                'labels': labels\n","            }\n","            sample = self.transforms(**sample)\n","            image = sample['image']\n","            \n","            target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1,0)\n","            \n","            return image, target\n","        \n","    def __len__(self) -> int:\n","        return self.image_ids.shape[0]"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"h3-oAySag_-n","executionInfo":{"status":"ok","timestamp":1680953523983,"user_tz":-330,"elapsed":4,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["def get_transform_train():\n","    return A.Compose([\n","        A.HorizontalFlip(p=0.5),\n","        A.RandomBrightnessContrast(p=0.2),\n","        ToTensorV2(p=1.0)\n","    ], bbox_params={'format':'pascal_voc', 'label_fields': ['labels']})\n","\n","def get_transform_valid():\n","    return A.Compose([\n","        ToTensorV2(p=1.0)\n","    ], bbox_params={'format': 'pascal_voc', 'label_fields':['labels']})"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1680953525102,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"cfWNyTMWg_-n","outputId":"f0277c3e-9316-43af-f4e2-d6b763fa2947"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["def collate_fn(batch):\n","    return tuple(zip(*batch))\n","\n","train_dataset = VOCDataset(train_df, IMG_PATH , get_transform_train())\n","valid_dataset = VOCDataset(valid_df, IMG_PATH, get_transform_valid())\n","\n","\n","# split the dataset in train and test set\n","indices = torch.randperm(len(train_dataset)).tolist()\n","\n","\n","train_data_loader = DataLoader(\n","    train_dataset,\n","    batch_size=4,\n","    shuffle=True,\n","    num_workers=4,\n","    collate_fn=collate_fn\n",")\n","\n","valid_data_loader = DataLoader(\n","    valid_dataset,\n","    batch_size=4,\n","    shuffle=False,\n","    num_workers=4,\n","    collate_fn=collate_fn\n",")"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"VV2IexHNg_-o","executionInfo":{"status":"ok","timestamp":1680953526831,"user_tz":-330,"elapsed":3,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1svj90JLbHofTtb_C9Lyxw-z4gAlsgx5R"},"executionInfo":{"elapsed":30182,"status":"ok","timestamp":1680953560190,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"DIdYOvrkg_-o","outputId":"b594201f-8452-4785-e494-7f62ab278aa1"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["images, targets= next(iter(train_data_loader))\n","images = list(image.to(device) for image in images)\n","targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","plt.figure(figsize=(20,20))\n","for i, (image, target) in enumerate(zip(images, targets)):\n","    plt.subplot(2,2, i+1)\n","    boxes = targets[i]['boxes'].cpu().numpy().astype(np.int32)\n","    sample = images[i].permute(1,2,0).cpu().numpy()\n","    names = targets[i]['labels'].cpu().numpy().astype(np.int64)\n","    for i,box in enumerate(boxes):\n","        cv2.rectangle(sample,\n","                      (box[0], box[1]),\n","                      (box[2], box[3]),\n","                      (0, 0, 220), 2)\n","        cv2.putText(sample, classes[names[i]], (box[0],box[1]+15),cv2.FONT_HERSHEY_COMPLEX ,0.5,(0,220,0),1,cv2.LINE_AA)  \n","\n","    plt.axis('off')\n","    plt.imshow(sample)\n","    "]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1680953560570,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"MZuDSLpIg_-p","outputId":"d9554aaf-c43f-48f1-b9ed-ee2d6d2bd710"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["# load a model; pre-trained on COCO\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"ovW_8cxmg_-p","executionInfo":{"status":"ok","timestamp":1680953560570,"user_tz":-330,"elapsed":4,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["num_classes = 12\n","\n","# get number of input features for the classifier\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","\n","# replace the pre-trained head with a new one\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"CavTpFzNg_-q","executionInfo":{"status":"ok","timestamp":1680953567001,"user_tz":-330,"elapsed":427,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[],"source":["model.to(device)\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005, weight_decay=0.0005)\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7287,"status":"ok","timestamp":1680953577030,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"4JyxrgvJg_-q","outputId":"4fa201cd-3111-4522-a93c-ef85ffb573e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n","  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-31s6g0lp\n","  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-31s6g0lp\n","  Resolved https://github.com/cocodataset/cocoapi.git to commit 8c9bcc3cf640524c4c20a9c40e89cb6a2f2fa0e9\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.9/dist-packages (from pycocotools==2.0) (67.6.1)\n","Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.9/dist-packages (from pycocotools==2.0) (0.29.34)\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from pycocotools==2.0) (3.7.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.11.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (3.0.9)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (8.4.0)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (5.12.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (23.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.8.2)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.22.4)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.4.4)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (4.39.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.0.7)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib>=2.1.0->pycocotools==2.0) (3.15.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0) (1.16.0)\n"]}],"source":["!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":604,"status":"ok","timestamp":1680953577623,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"kKqulq9Lg_-r","outputId":"d8103e01-9d28-4dd4-f64e-4d78ba0d46b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'vision' already exists and is not an empty directory.\n"]}],"source":["!git clone https://github.com/pytorch/vision.git\n","!cd vision;cp references/detection/utils.py ../;cp references/detection/transforms.py ../;cp references/detection/coco_eval.py ../;cp references/detection/engine.py ../;cp references/detection/coco_utils.py ../"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1680953577623,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"VggsFCZ5g_-r"},"outputs":[],"source":["from engine import train_one_epoch, evaluate\n","import utils"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317400,"status":"ok","timestamp":1680953898115,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"K-Idxjreg_-r","outputId":"011f7ab5-5127-4d09-eebe-f65874f2b0b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: [0]  [  0/234]  eta: 0:50:19  lr: 0.000026  loss: 5.1418 (5.1418)  loss_classifier: 2.7267 (2.7267)  loss_box_reg: 0.2778 (0.2778)  loss_objectness: 1.5747 (1.5747)  loss_rpn_box_reg: 0.5627 (0.5627)  time: 12.9032  data: 3.4647  max mem: 4239\n","Epoch: [0]  [ 10/234]  eta: 0:09:01  lr: 0.000241  loss: 3.7628 (4.0254)  loss_classifier: 2.6887 (2.6490)  loss_box_reg: 0.2690 (0.2704)  loss_objectness: 0.4815 (0.6354)  loss_rpn_box_reg: 0.5627 (0.4707)  time: 2.4179  data: 0.4363  max mem: 4599\n","Epoch: [0]  [ 20/234]  eta: 0:07:00  lr: 0.000455  loss: 3.6159 (3.6848)  loss_classifier: 2.4364 (2.4020)  loss_box_reg: 0.2643 (0.2762)  loss_objectness: 0.4049 (0.5558)  loss_rpn_box_reg: 0.3991 (0.4507)  time: 1.4196  data: 0.1384  max mem: 4743\n","Epoch: [0]  [ 30/234]  eta: 0:05:58  lr: 0.000670  loss: 2.6337 (3.2240)  loss_classifier: 1.7599 (2.0651)  loss_box_reg: 0.2719 (0.2891)  loss_objectness: 0.2928 (0.4570)  loss_rpn_box_reg: 0.3981 (0.4128)  time: 1.3923  data: 0.1275  max mem: 4743\n","Epoch: [0]  [ 40/234]  eta: 0:05:15  lr: 0.000884  loss: 1.6922 (2.8035)  loss_classifier: 0.9826 (1.7277)  loss_box_reg: 0.2709 (0.2769)  loss_objectness: 0.2058 (0.3998)  loss_rpn_box_reg: 0.3551 (0.3991)  time: 1.2673  data: 0.0910  max mem: 4743\n","Epoch: [0]  [ 50/234]  eta: 0:04:44  lr: 0.001098  loss: 1.2500 (2.4744)  loss_classifier: 0.5230 (1.4798)  loss_box_reg: 0.1955 (0.2667)  loss_objectness: 0.1901 (0.3566)  loss_rpn_box_reg: 0.2783 (0.3713)  time: 1.2234  data: 0.0710  max mem: 4743\n","Epoch: [0]  [ 60/234]  eta: 0:04:20  lr: 0.001313  loss: 1.0693 (2.2498)  loss_classifier: 0.4213 (1.3094)  loss_box_reg: 0.2049 (0.2593)  loss_objectness: 0.1642 (0.3254)  loss_rpn_box_reg: 0.2591 (0.3556)  time: 1.2323  data: 0.0713  max mem: 4743\n","Epoch: [0]  [ 70/234]  eta: 0:04:00  lr: 0.001527  loss: 1.1890 (2.1085)  loss_classifier: 0.4456 (1.1866)  loss_box_reg: 0.2531 (0.2613)  loss_objectness: 0.1831 (0.3110)  loss_rpn_box_reg: 0.3040 (0.3496)  time: 1.2499  data: 0.0837  max mem: 4743\n","Epoch: [0]  [ 80/234]  eta: 0:03:41  lr: 0.001741  loss: 1.1890 (1.9834)  loss_classifier: 0.4043 (1.0870)  loss_box_reg: 0.2822 (0.2602)  loss_objectness: 0.1581 (0.2956)  loss_rpn_box_reg: 0.2985 (0.3404)  time: 1.2628  data: 0.0992  max mem: 4743\n","Epoch: [0]  [ 90/234]  eta: 0:03:24  lr: 0.001956  loss: 1.1038 (1.9016)  loss_classifier: 0.3739 (1.0147)  loss_box_reg: 0.2578 (0.2659)  loss_objectness: 0.1581 (0.2851)  loss_rpn_box_reg: 0.2954 (0.3360)  time: 1.2709  data: 0.0977  max mem: 4743\n","Epoch: [0]  [100/234]  eta: 0:03:09  lr: 0.002170  loss: 1.0929 (1.8179)  loss_classifier: 0.3571 (0.9484)  loss_box_reg: 0.2450 (0.2641)  loss_objectness: 0.1672 (0.2746)  loss_rpn_box_reg: 0.2855 (0.3309)  time: 1.3219  data: 0.1189  max mem: 4743\n","Epoch: [0]  [110/234]  eta: 0:02:53  lr: 0.002385  loss: 1.0167 (1.7439)  loss_classifier: 0.3241 (0.8920)  loss_box_reg: 0.2416 (0.2642)  loss_objectness: 0.1534 (0.2621)  loss_rpn_box_reg: 0.2766 (0.3255)  time: 1.2917  data: 0.1103  max mem: 4814\n","Epoch: [0]  [120/234]  eta: 0:02:37  lr: 0.002599  loss: 0.9790 (1.6762)  loss_classifier: 0.2932 (0.8393)  loss_box_reg: 0.2364 (0.2598)  loss_objectness: 0.1507 (0.2553)  loss_rpn_box_reg: 0.2506 (0.3217)  time: 1.2199  data: 0.0809  max mem: 4814\n","Epoch: [0]  [130/234]  eta: 0:02:23  lr: 0.002813  loss: 1.0297 (1.6350)  loss_classifier: 0.2748 (0.7992)  loss_box_reg: 0.2194 (0.2620)  loss_objectness: 0.1559 (0.2532)  loss_rpn_box_reg: 0.2902 (0.3205)  time: 1.2555  data: 0.0939  max mem: 4814\n","Epoch: [0]  [140/234]  eta: 0:02:09  lr: 0.003028  loss: 1.0192 (1.5833)  loss_classifier: 0.2972 (0.7621)  loss_box_reg: 0.3000 (0.2635)  loss_objectness: 0.1446 (0.2444)  loss_rpn_box_reg: 0.2346 (0.3133)  time: 1.3538  data: 0.1184  max mem: 4814\n","Epoch: [0]  [150/234]  eta: 0:01:55  lr: 0.003242  loss: 0.8699 (1.5376)  loss_classifier: 0.2590 (0.7274)  loss_box_reg: 0.2639 (0.2601)  loss_objectness: 0.1334 (0.2387)  loss_rpn_box_reg: 0.2433 (0.3115)  time: 1.3872  data: 0.1222  max mem: 4913\n","Epoch: [0]  [160/234]  eta: 0:01:41  lr: 0.003456  loss: 0.8213 (1.4947)  loss_classifier: 0.2519 (0.6966)  loss_box_reg: 0.2164 (0.2579)  loss_objectness: 0.1564 (0.2338)  loss_rpn_box_reg: 0.2653 (0.3065)  time: 1.3219  data: 0.1050  max mem: 4945\n","Epoch: [0]  [170/234]  eta: 0:01:27  lr: 0.003671  loss: 0.8213 (1.4623)  loss_classifier: 0.2524 (0.6718)  loss_box_reg: 0.2460 (0.2601)  loss_objectness: 0.1549 (0.2287)  loss_rpn_box_reg: 0.2049 (0.3018)  time: 1.2765  data: 0.0927  max mem: 4945\n","Epoch: [0]  [180/234]  eta: 0:01:13  lr: 0.003885  loss: 0.9099 (1.4359)  loss_classifier: 0.2735 (0.6506)  loss_box_reg: 0.3186 (0.2623)  loss_objectness: 0.1249 (0.2238)  loss_rpn_box_reg: 0.2132 (0.2991)  time: 1.2754  data: 0.0868  max mem: 4945\n","Epoch: [0]  [190/234]  eta: 0:00:59  lr: 0.004100  loss: 0.9115 (1.4111)  loss_classifier: 0.2586 (0.6303)  loss_box_reg: 0.2919 (0.2641)  loss_objectness: 0.1421 (0.2209)  loss_rpn_box_reg: 0.2419 (0.2958)  time: 1.2473  data: 0.0733  max mem: 4945\n","Epoch: [0]  [200/234]  eta: 0:00:45  lr: 0.004314  loss: 0.8106 (1.3771)  loss_classifier: 0.2120 (0.6082)  loss_box_reg: 0.2245 (0.2600)  loss_objectness: 0.1474 (0.2174)  loss_rpn_box_reg: 0.2086 (0.2915)  time: 1.2256  data: 0.0675  max mem: 4945\n","Epoch: [0]  [210/234]  eta: 0:00:32  lr: 0.004528  loss: 0.8437 (1.3591)  loss_classifier: 0.2118 (0.5915)  loss_box_reg: 0.2318 (0.2617)  loss_objectness: 0.1474 (0.2153)  loss_rpn_box_reg: 0.2344 (0.2906)  time: 1.2286  data: 0.0788  max mem: 4945\n","Epoch: [0]  [220/234]  eta: 0:00:18  lr: 0.004743  loss: 0.8857 (1.3357)  loss_classifier: 0.2298 (0.5745)  loss_box_reg: 0.2485 (0.2612)  loss_objectness: 0.1333 (0.2119)  loss_rpn_box_reg: 0.2587 (0.2881)  time: 1.2289  data: 0.0818  max mem: 4945\n","Epoch: [0]  [230/234]  eta: 0:00:05  lr: 0.004957  loss: 0.8280 (1.3178)  loss_classifier: 0.2246 (0.5604)  loss_box_reg: 0.2164 (0.2601)  loss_objectness: 0.1460 (0.2102)  loss_rpn_box_reg: 0.2609 (0.2871)  time: 1.2553  data: 0.0939  max mem: 4945\n","Epoch: [0]  [233/234]  eta: 0:00:01  lr: 0.005000  loss: 0.8828 (1.3127)  loss_classifier: 0.2249 (0.5563)  loss_box_reg: 0.2185 (0.2601)  loss_objectness: 0.1497 (0.2099)  loss_rpn_box_reg: 0.2609 (0.2864)  time: 1.2142  data: 0.0829  max mem: 4945\n","Epoch: [0] Total time: 0:05:11 (1.3317 s / it)\n","creating index...\n","index created!\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Test:  [0/1]  eta: 0:00:02  model_time: 0.4669 (0.4669)  evaluator_time: 0.1738 (0.1738)  time: 2.1662  data: 1.4865  max mem: 4945\n","Test: Total time: 0:00:02 (2.3015 s / it)\n","Averaged stats: model_time: 0.4669 (0.4669)  evaluator_time: 0.1738 (0.1738)\n","Accumulating evaluation results...\n","DONE (t=0.01s).\n","IoU metric: bbox\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.042\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.116\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.023\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.043\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.066\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.063\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.091\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.077\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.136\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n","CPU times: user 2min 26s, sys: 10.8 s, total: 2min 37s\n","Wall time: 5min 16s\n"]}],"source":["%%time\n","# let's train it for 1 epoch\n","num_epochs = 1\n","\n","for epoch in range(num_epochs):\n","    # train for one epoch, printing every 10 iterations\n","    train_one_epoch(model, optimizer, train_data_loader, device, epoch, print_freq=10)\n","    # update the learning rate\n","    lr_scheduler.step()\n","    # evaluate on the test dataset\n","    evaluate(model, valid_data_loader, device=device)"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":1100,"status":"ok","timestamp":1680953905796,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"M8oQFNLMg_-s"},"outputs":[],"source":["torch.save(model.state_dict(), 'faster_rcnn_state2.pth')"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1850,"status":"ok","timestamp":1680953909517,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"b-G2lTWRg_-s","outputId":"1aebbbca-a994-4f8d-aba9-3bc674ac7ef0"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained_backbone' is deprecated since 0.13 and may be removed in the future, please use 'weights_backbone' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights_backbone' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights_backbone=None`.\n","  warnings.warn(msg)\n"]}],"source":["# load  a model; pre-trained on COCO\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, pretrained_backbone=False)\n","\n","WEIGHTS_FILE = \"./faster_rcnn_state2.pth\"\n","\n","num_classes = 12\n","\n","# get number of input features for the classifier\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","\n","# replace the pre-trained head with a new one\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","\n","# Load the traines weights\n","model.load_state_dict(torch.load(WEIGHTS_FILE))\n","\n","model = model.to(device)\n"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1680953911226,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"},"user_tz":-330},"id":"ISQInM55g_-t"},"outputs":[],"source":["def obj_detector(img):\n","    img = cv2.imread(img, cv2.IMREAD_COLOR)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n","\n","\n","    img /= 255.0\n","    img = torch.from_numpy(img)\n","    img = img.unsqueeze(0)\n","    img = img.permute(0,3,1,2)\n","    \n","    model.eval()\n","\n","    detection_threshold = 0.70\n","    \n","    img = list(im.to(device) for im in img)\n","    output = model(img)\n","\n","    for i , im in enumerate(img):\n","        boxes = output[i]['boxes'].data.cpu().numpy()\n","        scores = output[i]['scores'].data.cpu().numpy()\n","        labels = output[i]['labels'].data.cpu().numpy()\n","\n","        labels = labels[scores >= detection_threshold]\n","        boxes = boxes[scores >= detection_threshold].astype(np.int32)\n","        scores = scores[scores >= detection_threshold]\n","\n","        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n","        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n","    \n","    sample = img[0].permute(1,2,0).cpu().numpy()\n","    sample = np.array(sample)\n","    boxes = output[0]['boxes'].data.cpu().numpy()\n","    name = output[0]['labels'].data.cpu().numpy()\n","    scores = output[0]['scores'].data.cpu().numpy()\n","    boxes = boxes[scores >= detection_threshold].astype(np.int32)\n","    names = name.tolist()\n","    \n","    return names, boxes, sample"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rlpYQbaDg_-t","outputId":"fe6dce7a-9850-45cb-d47e-605dd27be565","executionInfo":{"status":"ok","timestamp":1680953974042,"user_tz":-330,"elapsed":57266,"user":{"displayName":"Alf Cress","userId":"12296072416369396371"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["0 ./test1/0000007_05999_d_0000038.jpg\n","1 ./test1/0000002_00005_d_0000014.jpg\n","2 ./test1/0000072_00000_d_0000001.jpg\n","3 ./test1/0000107_02196_d_0000055.jpg\n","4 ./test1/0000072_07660_d_0000012.jpg\n","5 ./test1/0000008_00889_d_0000039.jpg\n","6 ./test1/0000008_03499_d_0000043.jpg\n","7 ./test1/0000008_03999_d_0000044.jpg\n","8 ./test1/0000008_04499_d_0000045.jpg\n","9 ./test1/0000008_02999_d_0000042.jpg\n","10 ./test1/0000008_02499_d_0000041.jpg\n","11 ./test1/0000008_01999_d_0000040.jpg\n","12 ./test1/0000036_00500_d_0000046.jpg\n","13 ./test1/0000031_02000_d_0000041.jpg\n","14 ./test1/0000031_03527_d_0000043.jpg\n","15 ./test1/0000031_00000_d_0000037.jpg\n","16 ./test1/9999999_00301_d_0000133.jpg\n","17 ./test1/9999999_00299_d_0000132.jpg\n","18 ./test1/0000040_04284_d_0000071.jpg\n","19 ./test1/0000040_02454_d_0000068.jpg\n","20 ./test1/0000040_03288_d_0000069.jpg\n","21 ./test1/0000040_03752_d_0000070.jpg\n","22 ./test1/0000040_01500_d_0000067.jpg\n","23 ./test1/0000040_01000_d_0000066.jpg\n","24 ./test1/0000039_05300_d_0000061.jpg\n","25 ./test1/0000039_00000_d_0000055.jpg\n","26 ./test1/0000037_01494_d_0000052.jpg\n","27 ./test1/0000039_05625_d_0000062.jpg\n","28 ./test1/0000036_03591_d_0000048.jpg\n","29 ./test1/9999999_00330_d_0000144.jpg\n","30 ./test1/9999999_00332_d_0000145.jpg\n","31 ./test1/9999999_00328_d_0000143.jpg\n","32 ./test1/9999999_00326_d_0000142.jpg\n","33 ./test1/9999999_00322_d_0000141.jpg\n","34 ./test1/9999999_00320_d_0000140.jpg\n","35 ./test1/9999999_00318_d_0000139.jpg\n","36 ./test1/9999999_00313_d_0000138.jpg\n","37 ./test1/9999999_00309_d_0000137.jpg\n","38 ./test1/9999999_00307_d_0000136.jpg\n","39 ./test1/9999999_00303_d_0000134.jpg\n","40 ./test1/9999999_00305_d_0000135.jpg\n","41 ./test1/9999999_00354_d_0000154.jpg\n","42 ./test1/9999999_00356_d_0000155.jpg\n","43 ./test1/9999999_00348_d_0000153.jpg\n","44 ./test1/9999999_00346_d_0000152.jpg\n","45 ./test1/9999999_00342_d_0000150.jpg\n","46 ./test1/9999999_00344_d_0000151.jpg\n","47 ./test1/9999999_00340_d_0000149.jpg\n","48 ./test1/9999999_00338_d_0000148.jpg\n","49 ./test1/9999999_00336_d_0000147.jpg\n"]}],"source":["pred_path = \"./test1\"\n","pred_files = [os.path.join(pred_path,f) for f in os.listdir(pred_path)]\n","\n","for i, images in enumerate(pred_files):\n","    print(i,images)\n","    names,boxes,sample = obj_detector(images)\n","\n","    img = cv2.imread(images)\n","    \n","    for i,box in enumerate(boxes):\n","        cv2.rectangle(img,\n","                      (box[0], box[1]),\n","                      (box[2], box[3]),\n","                      (0, 220, 0), 2)  \n","\n","    cv2.imwrite(f'./test2/{images[7:]}',img)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1V0y9Jo0CKCAU2vg6hy8V9vHxUauNk0lz","timestamp":1679820769372}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}